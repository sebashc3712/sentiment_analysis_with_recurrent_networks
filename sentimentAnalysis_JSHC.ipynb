{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook a implmentation of deep learning in sentiment analysis is presented. The dataset to study contains tweets of an airline with positive, negative or neutral sentiment. Recurrent neural networks are used to build the model, and random search and grid search for tuning the hyparameters. Besides that a pre-trained Embedding is used to add a Embedding Layer in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense, Masking\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.optimizers\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 20)\n",
      "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
      "       '_last_judgment_at', 'airline_sentiment',\n",
      "       'airline_sentiment:confidence', 'negativereason',\n",
      "       'negativereason:confidence', 'airline', 'airline_sentiment_gold',\n",
      "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
      "       'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-25 05:24:00</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:00</td>\n",
       "      <td>570306000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-25 01:53:00</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:00</td>\n",
       "      <td>570301000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-25 10:01:00</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:00</td>\n",
       "      <td>570301000000000000</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-25 03:05:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:00</td>\n",
       "      <td>570301000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-25 05:50:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:00</td>\n",
       "      <td>570301000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments   _last_judgment_at  \\\n",
       "0  681448150    False   finalized                   3 2015-02-25 05:24:00   \n",
       "1  681448153    False   finalized                   3 2015-02-25 01:53:00   \n",
       "2  681448156    False   finalized                   3 2015-02-25 10:01:00   \n",
       "3  681448158    False   finalized                   3 2015-02-25 03:05:00   \n",
       "4  681448159    False   finalized                   3 2015-02-25 05:50:00   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "        tweet_created            tweet_id tweet_location  \\\n",
       "0 2015-02-24 11:35:00  570306000000000000            NaN   \n",
       "1 2015-02-24 11:15:00  570301000000000000            NaN   \n",
       "2 2015-02-24 11:15:00  570301000000000000      Lets Play   \n",
       "3 2015-02-24 11:15:00  570301000000000000            NaN   \n",
       "4 2015-02-24 11:14:00  570301000000000000            NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Pacific Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset=pd.read_excel('dataset_tweets.xlsx', parse_dates=['tweet_created'])\n",
    "print(dataset.shape)\n",
    "print(dataset.columns)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the columns to use\n",
    "dataset=dataset[['airline_sentiment','text']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica it\\'s really aggressive to blast obnoxious \"entertainment\" in your guests\\' faces &amp; they have little recourse'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica did you know that suicide is the second leading cause of death among teens 10-24'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5596b38e10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAU7klEQVR4nO3de7SldX3f8fcHBhAkcnFGq4AZgtMYtEmUWVwkTY24EJNUqIIZKzIauogtitraVLPaQiVmYbVFQ9SECAqGFHE0isYKFIXVYrkMQrgMIlNAGCEyOoC3iI58+8fzO7IZzpnfmWH2ucx5v9ba6zzP77l999l7n895Lvv3pKqQJGlzdpjtAiRJc59hIUnqMiwkSV2GhSSpy7CQJHUtmu0CxmHx4sW1dOnS2S5DkuaV66+//jtVtWSyadtlWCxdupTVq1fPdhmSNK8k+eZU0zwMJUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6touv8EtaX44/KzDZ7uE7d5Vb7lqm6zHPQtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqSusYZFkrcnuTXJLUn+R5KnJNk/yTVJ7kjyySQ7t3l3aeNr2/SlI+t5V2u/PcnLx1mzJOmJxhYWSfYBTgGWV9ULgB2BFcB7gTOrahnwIHBiW+RE4MGqei5wZpuPJAe25Z4PHAV8OMmO46pbkvRE4z4MtQjYNckiYDfgfuClwKo2/TzgmDZ8dBunTT8iSVr7hVX1SFXdBawFDh5z3ZKkEWMLi6r6FvB+4B6GkHgYuB54qKo2ttnWAfu04X2Ae9uyG9v8Tx9tn2SZn0tyUpLVSVavX79+2z8hSVrAxnkYai+GvYL9gWcDTwVeMcmsNbHIFNOman98Q9XZVbW8qpYvWbJk64qWJE1qnIehXgbcVVXrq+qnwGeAFwN7tsNSAPsC97XhdcB+AG36HsCG0fZJlpEkzYBxhsU9wKFJdmvnHo4A1gBfAY5t86wEPteGL27jtOlfrqpq7Sva1VL7A8uAa8dYtyRpE4v6s2ydqromySrga8BG4AbgbOBvgQuT/HFrO6ctcg7wiSRrGfYoVrT13JrkIoag2QicXFU/G1fdkqQnGltYAFTVqcCpmzTfySRXM1XVj4HjpljPe4D3bPMCJUnT4je4JUldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqSusYZFkj2TrEry9SS3JTksyd5JLktyR/u5V5s3Sf40ydokNyV50ch6Vrb570iycpw1S5KeaNx7Fh8EvlRVzwN+DbgNeCdweVUtAy5v4wCvAJa1x0nARwCS7A2cChwCHAycOhEwkqSZMbawSPI04DeBcwCq6idV9RBwNHBem+084Jg2fDRwfg2uBvZM8izg5cBlVbWhqh4ELgOOGlfdkqQnGueexS8B64GPJbkhyUeTPBV4ZlXdD9B+PqPNvw9w78jy61rbVO2SpBkyzrBYBLwI+EhVvRD4IY8dcppMJmmrzbQ/fuHkpCSrk6xev3791tQrSZrCOMNiHbCuqq5p46sYwuPb7fAS7ecDI/PvN7L8vsB9m2l/nKo6u6qWV9XyJUuWbNMnIkkL3djCoqr+Hrg3yS+3piOANcDFwMQVTSuBz7Xhi4ET2lVRhwIPt8NUlwBHJtmrndg+srVJkmbIojGv/y3ABUl2Bu4E3sgQUBclORG4BziuzftF4LeBtcCP2rxU1YYkpwPXtfneXVUbxly3JGnEWMOiqm4Elk8y6YhJ5i3g5CnWcy5w7ratTpI0XX6DW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6phUWSS6fTpskafu02b6hkjwF2A1Y3Hp8nbi3xNOAZ4+5NknSHNHrSPAPgLcxBMP1PBYW3wM+NMa6JElzyGbDoqo+CHwwyVuq6qwZqkmSNMdMq4vyqjoryYuBpaPLVNX5Y6pLkjSHTCssknwCOAC4EfhZay7AsJCkBWC6Nz9aDhzYblAkSVpgpvs9i1uAfzTOQiRJc9d09ywWA2uSXAs8MtFYVa8cS1WSpDllumFx2jiLkCTNbdO9GurKcRciSZq7pns11PcZrn4C2BnYCfhhVT1tXIVJkuaO6e5Z/MLoeJJjgIPHUpEkac7Zql5nq+qzwEu3cS2SpDlquoehXjUyugPD9y78zoUkLRDTvRrqn48MbwTuBo7e5tVIkuak6Z6zeOO4C5EkzV3TvfnRvkn+JskDSb6d5NNJ9h13cZKkuWG6J7g/BlzMcF+LfYDPtzZJ0gIw3bBYUlUfq6qN7fFxYMkY65IkzSHTDYvvJDk+yY7tcTzw3XEWJkmaO6YbFr8PvAb4e+B+4FjAk96StEBM99LZ04GVVfUgQJK9gfczhIgkaTs33T2LX50ICoCq2gC8cDwlSZLmmumGxQ5J9poYaXsW090rkSTNc9P9g//fgK8mWcXQzcdrgPeMrSpJ0pwyrT2LqjofeDXwbWA98Kqq+sR0lm1XT92Q5AttfP8k1yS5I8knk+zc2ndp42vb9KUj63hXa789ycu37ClKkp6safc6W1VrqurPquqsqlqzBdt4K3DbyPh7gTOrahnwIHBiaz8ReLCqnguc2eYjyYHACuD5wFHAh5PsuAXblyQ9SVvVRfl0tS5Bfgf4aBsPQ9fmq9os5wHHtOGj2zht+hFt/qOBC6vqkaq6C1iL99KQpBk11rAAPgD8IfBoG3868FBVbWzj6xi6D6H9vBegTX+4zf/z9kmWkSTNgLGFRZLfBR6oqutHmyeZtTrTNrfM6PZOSrI6yer169dvcb2SpKmNc8/icOCVSe4GLmQ4/PQBYM8kE1dh7Qvc14bXAfsBtOl7ABtG2ydZ5ueq6uyqWl5Vy5cssdsqSdqWxhYWVfWuqtq3qpYynKD+clW9DvgKQ3chACuBz7Xhi9s4bfqXq6pa+4p2tdT+wDLg2nHVLUl6otn4Yt1/AC5M8sfADcA5rf0c4BNJ1jLsUawAqKpbk1wErGG4S9/JVfWzmS9bkhauGQmLqroCuKIN38kkVzNV1Y+B46ZY/j34JUBJmjXjvhpKkrQdMCwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkrpm4+ZHc8pB//782S5hQbj+fSfMdgmSngT3LCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6lrwNz/S/HbPu//JbJew3XvOf755tkvQHOCehSSpy7CQJHUZFpKkLsNCktQ1trBIsl+SryS5LcmtSd7a2vdOclmSO9rPvVp7kvxpkrVJbkryopF1rWzz35Fk5bhqliRNbpx7FhuBf1dVvwIcCpyc5EDgncDlVbUMuLyNA7wCWNYeJwEfgSFcgFOBQ4CDgVMnAkaSNDPGFhZVdX9Vfa0Nfx+4DdgHOBo4r812HnBMGz4aOL8GVwN7JnkW8HLgsqraUFUPApcBR42rbknSE83IOYskS4EXAtcAz6yq+2EIFOAZbbZ9gHtHFlvX2qZq33QbJyVZnWT1+vXrt/VTkKQFbexhkWR34NPA26rqe5ubdZK22kz74xuqzq6q5VW1fMmSJVtXrCRpUmMNiyQ7MQTFBVX1mdb87XZ4ifbzgda+DthvZPF9gfs20y5JmiHjvBoqwDnAbVX130cmXQxMXNG0EvjcSPsJ7aqoQ4GH22GqS4Ajk+zVTmwf2dokSTNknH1DHQ68Hrg5yY2t7Y+AM4CLkpwI3AMc16Z9EfhtYC3wI+CNAFW1IcnpwHVtvndX1YYx1i1J2sTYwqKq/g+Tn28AOGKS+Qs4eYp1nQucu+2qkyRtCb/BLUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1zZuwSHJUktuTrE3yztmuR5IWknkRFkl2BD4EvAI4EHhtkgNntypJWjjmRVgABwNrq+rOqvoJcCFw9CzXJEkLRqpqtmvoSnIscFRV/as2/nrgkKp688g8JwEntdFfBm6f8UJnzmLgO7NdhLaar9/8tb2/dr9YVUsmm7BopivZSpmk7XEpV1VnA2fPTDmzK8nqqlo+23Vo6/j6zV8L+bWbL4eh1gH7jYzvC9w3S7VI0oIzX8LiOmBZkv2T7AysAC6e5ZokacGYF4ehqmpjkjcDlwA7AudW1a2zXNZsWhCH27Zjvn7z14J97ebFCW5J0uyaL4ehJEmzyLCQJHUZFvNUkqVJ/uVWLvuDbV2P+pK8KckJbfgNSZ49Mu2j9kowvyTZM8m/GRl/dpJVs1nTOHnOYp5K8hLgHVX1u5NMW1RVGzez7A+qavdx1qfNS3IFw+u3erZr0dZJshT4QlW9YJZLmRHuWcywtkdwW5K/THJrkkuT7JrkgCRfSnJ9kv+d5Hlt/o+3b7BPLD+xV3AG8E+T3Jjk7e0/1U8l+TxwaZLdk1ye5GtJbk5i9yhPQnvdvp7kvCQ3JVmVZLckRyS5of2Oz02yS5v/jCRr2rzvb22nJXlHez2XAxe012/XJFckWZ7kXyf5ryPbfUOSs9rw8Umubcv8ReszTVPYis/aAUmuTnJdkndPfNY281k6AzigvR7va9u7pS1zTZLnj9RyRZKDkjy1vU+ua++b+fO5rCofM/gAlgIbgV9v4xcBxwOXA8ta2yHAl9vwx4FjR5b/Qfv5Eob/aiba38Dw5cW92/gi4GlteDGwlsf2JH8w27+H+fZor1sBh7fxc4H/CNwL/OPWdj7wNmBvhu5mJn7fe7afpzHsTQBcASwfWf8VDAGyhKEftIn2/wn8BvArwOeBnVr7h4ETZvv3MpcfW/FZ+wLw2jb8ppHP2qSfpbb+WzbZ3i1t+O3Af2nDzwK+0Yb/BDh+4n0BfAN46mz/rqbzcM9idtxVVTe24esZ3mQvBj6V5EbgLxjeYFvqsqra0IYD/EmSm4D/BewDPPNJVa17q+qqNvxXwBEMr+U3Wtt5wG8C3wN+DHw0yauAH013A1W1HrgzyaFJns7Qz9lVbVsHAde198gRwC9tg+e0vduSz9phwKfa8F+PrGNrPksXAce14deMrPdI4J1t21cATwGes8XPahbMiy/lbYceGRn+GcMb76Gq+vVJ5t1IO1yYJMDOm1nvD0eGX8fwX+pBVfXTJHczvDG19aZ1gq+GL5EezPAHfQXwZuClW7CdTzL8gfk68DdVVe21P6+q3rWFNS90W/JZm8oWf5aq6ltJvpvkV4HfA/6gTQrw6qqadx2dumcxN3wPuCvJcTCEQpJfa9PuZviPEoZu2Xdqw98HfmEz69wDeKC9uX8L+MVtXvXC85wkh7Xh1zL8l7k0yXNb2+uBK5PsDuxRVV9kOCw12R+mzb1+nwGOadv4ZGu7HDg2yTMAkuydxNd0y23us3Y18Oo2vGJkmak+S73P4IXAHzK8F25ubZcAb2nhT5IXPtknNFMMi7njdcCJSf4OuJXH7tfxl8A/S3Itw/HVib2Hm4CNSf4uydsnWd8FwPIkq9u6vz7W6heG24CV7XDE3sCZwBsZDmncDDwK/DnDH5AvtPmuZDh+vamPA38+cYJ7dEJVPQisYegu+trWtobhHMmlbb2XsXWHKjX1Z+1twL9tn7VnAQ+39kk/S1X1XeCqJLcked8k21nFEDoXjbSdzvAP303tZPjp2/SZjZGXzkrTkAV2meRClGQ34B/aYb8VDCe758/VSmPmOQtJGhwE/Fk7RPQQ8PuzXM+c4p6FJKnLcxaSpC7DQpLUZVhIkroMC0lSl2Gh7VqSLybZc4ppdydZ3Ia/OrOVTU+SP9pkfKx1ZpNut6UJXg2lBaddGhngTobO/L4zyyVNKTPcnbzfJ9FU3LPQdiPJZ1u307cmOam13Z1k8Uh31R8Gvgbst8myE91Rv6R1J70qQ5fkF4x0zXBQkivbNi5JMuU3qJOckse6KL+wtU3aPXWGbsg/k6Hb7DvSuihPcgawa/uW9wWT1HllkouSfCNDl+ivy9CF+c1JDmjzLUny6bbN65Ic3tpPa7VckeTOJKe00h/X7fY2eWG0fZjtbm99+NhWDx7rnn1X4Bbg6Qx9ay1m6G30UeDQkfnvBha34dGu3x8G9mX4Z+r/MnQRvhPwVWBJm+/3gHM3U8t9wC5teKKL8km7p2boXv5Ohj6IngJ8E9hvtK6R9Y7W+RBDtxS7AN/isS6x3wp8oA3/NfAbbfg5wG1t+LT2fHZpv5/vtue4lJFut334mHj4DW5tT05J8i/a8H7Ask2mf7Oqrp7Geq6tqnUAGbqSXsrwh/kFwGVtR2NH4P7NrOMmhpsbfRb4bGs7Enhlkne08dHuqS+vqofbNtcwdFZ3b6fO66rq/rbM/wMube03A7/Vhl8GHNhqBnhakonO7/62qh4BHknyAHZhr80wLLRdyHCb2ZcBh1XVjzLctnTTbqR/uOlyU9i0W+tFDOc4bq2qwyZf5Al+h+HeFq8E/lOGu6ZN2j11kkOm2OaW1PnoyPijI8vvwPA7+YdNtrnp8tPdphYoz1loe7EH8GALiucBh27j9d8OLEnrojzJThm5beaoJDswHEb6CkMX1XsCu7N13VP/NMlO/dmmdCnD/TQmauvdx6HX7bYWKMNC24svAYta992nM9ybYJupqp8AxwLvbV1b38hwx7XJ7Aj8Veu2/AbgzKp6iK3rnvrsNv8FW1n6KQzda9/UDm+9aXMzV7/bbS1QXjorSepyz0KS1OUJLelJSPIh4PBNmj9YVR+bjXqkcfEwlCSpy8NQkqQuw0KS1GVYSJK6DAtJUtf/B+FI7KNgkbhKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='airline_sentiment', data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph we can see that the data is unbalanced. However, in the exercise we will use tha data in this way. Another preprocessing for balancing the data is for further researchs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next functions uses regular expressions for deleting and replacing special characters in order to have a better corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'@\\w+')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Removing html tags\n",
    "    text = remove_tags(text)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # Single character removal\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "tweets=list(dataset['text'])\n",
    "for tweet in tweets:\n",
    "    x.append(preprocess_text(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the same tweets we called before don't have numbers and special characters now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' it really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' did you know that suicide is the second leading cause of death among teens '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next function converts the tweet into a sequence of integers using the Tokenizer from keras. Besides that other information of the token dictionary are extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(texts,\n",
    "                   lower=True,\n",
    "                   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'):\n",
    "\n",
    "    # Create the tokenizer object and train on texts\n",
    "    tokenizer = Tokenizer(lower=lower, filters=filters)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    # Create look-up dictionaries and reverse look-ups\n",
    "    word_idx = tokenizer.word_index\n",
    "    idx_word = tokenizer.index_word\n",
    "    num_words = len(word_idx) + 1\n",
    "    word_counts = tokenizer.word_counts\n",
    "\n",
    "    print(f'There are {num_words} unique words.')\n",
    "\n",
    "    # Convert text to sequences of integers\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    return word_idx, idx_word, num_words, word_counts, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12861 unique words.\n"
     ]
    }
   ],
   "source": [
    "word_idx,idx_word, num_words, word_counts,x=make_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 122, 3481, 1, 4299, 4300, 954, 10, 14, 2958, 3482, 53, 45, 17, 472, 2595]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[109, 3, 100, 15, 2360, 9, 2, 583, 1985, 728, 12, 1414, 1662, 2361]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the tweets converted into sequences, the labels (neagetive, positive and neutral) are converted into categorical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     neutral\n",
       "1    positive\n",
       "2     neutral\n",
       "3    negative\n",
       "4    negative\n",
       "Name: airline_sentiment, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def string_to_int(text):\n",
    "    if text=='positive':\n",
    "        return 0\n",
    "    elif text=='negative':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "y=list(map(string_to_int,dataset['airline_sentiment']))\n",
    "\n",
    "y=to_categorical(y, num_classes=3)\n",
    "\n",
    "print(y[0:5])\n",
    "dataset['airline_sentiment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the train_test_split method from scikitlearn, a padding method is applied in the data in order to having sequences with the same length. This method receives a length. That's why the maximum length in the sequences is calculated. So, if we have a maximum length of 10, when we apply padding to a sequence with 3 integers, 7 more zeros are added to the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_len(a):\n",
    "    result=0\n",
    "    for i in range(0,len(a)):\n",
    "        if len(a[i])>result:\n",
    "            result=len(a[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10248 10248\n"
     ]
    }
   ],
   "source": [
    "max_length=max_len(x)\n",
    "x = pad_sequences(x, padding='post', maxlen=max_length)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "print(len(x_train),len(y_train))\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the embedding, a pre-trained word embedding is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 101)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from keras.utils import get_file\n",
    "\n",
    "# Vectors to use\n",
    "glove_vectors = '/home/ubuntu/.keras/datasets/glove.6B.zip'\n",
    "\n",
    "# Download word embeddings if they are not present\n",
    "if not os.path.exists(glove_vectors):\n",
    "    glove_vectors = get_file('glove.6B.zip',\n",
    "                             'http://nlp.stanford.edu/data/glove.6B.zip')\n",
    "    os.system(f'unzip {glove_vectors}')\n",
    "\n",
    "# Load in unzipped file\n",
    "glove_vectors = './glove.6B.100d.txt'\n",
    "glove = np.loadtxt(glove_vectors, dtype='str', comments=None)\n",
    "glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-3.9551e-01,  5.4660e-01,  5.0315e-01, -6.3682e-01, -4.5470e-01,\n",
       "         3.0889e-01, -4.9240e-02,  2.7191e-01,  3.1562e-01, -3.2879e-01,\n",
       "         2.5089e-01,  1.4508e-01,  3.5136e-01, -2.2793e-01, -1.5894e-01,\n",
       "        -5.1527e-01, -2.7978e-01,  3.6470e-01, -3.9425e-01,  3.3299e-01,\n",
       "         4.3051e-01,  1.8300e-01,  2.5095e-01, -1.8547e-01,  3.4698e-01,\n",
       "         5.5137e-02, -4.5979e-01, -8.2963e-01, -1.8523e-02, -3.6772e-01,\n",
       "         4.5566e-02,  7.1052e-01, -2.2782e-02, -8.0889e-02,  2.0685e-01,\n",
       "         4.9855e-01, -5.9794e-02, -8.0048e-03, -2.3823e-01, -3.3759e-01,\n",
       "        -2.4201e-01, -2.3788e-01, -1.1362e-03, -4.0395e-01, -4.4859e-01,\n",
       "        -3.2189e-01,  4.8405e-01, -2.7999e-02,  1.0148e-01, -9.3585e-01,\n",
       "        -8.7522e-02, -3.9959e-01,  3.6545e-01,  1.3726e+00, -3.0713e-01,\n",
       "        -2.5940e+00,  2.2431e-01, -4.1168e-02,  1.7765e+00,  4.0010e-01,\n",
       "        -1.0996e-01,  1.4178e+00, -2.6154e-01,  1.8617e-01,  7.9328e-01,\n",
       "        -1.1709e-01,  8.7541e-01,  4.3911e-01,  3.4711e-01, -2.8515e-01,\n",
       "         7.6269e-02, -6.3038e-01,  1.6408e-01, -3.7053e-01,  5.8485e-01,\n",
       "        -1.5472e-01, -2.6382e-01, -1.8590e-01, -7.5228e-01, -1.5752e-01,\n",
       "         7.8539e-01, -1.8846e-02, -8.0130e-01,  1.5561e-01, -1.8624e+00,\n",
       "        -1.6969e-01,  1.9419e-01, -3.0683e-01, -7.8067e-01, -4.9689e-01,\n",
       "        -1.8256e-01, -4.2016e-02, -2.6290e-01,  5.8531e-02, -4.4664e-01,\n",
       "        -9.9765e-02, -4.3050e-01, -2.3693e-01, -1.4519e-02,  3.1981e-01]),\n",
       " 'so')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = glove[:, 1:].astype('float')\n",
    "words = glove[:, 0]\n",
    "\n",
    "del glove\n",
    "\n",
    "vectors[100], words[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, only the common words between the dataset and the embedding stay in the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 3383 words without pre-trained embeddings.\n"
     ]
    }
   ],
   "source": [
    "word_lookup = {word: vector for word, vector in zip(words, vectors)}\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, vectors.shape[1]))\n",
    "\n",
    "not_found = 0\n",
    "\n",
    "for i, word in enumerate(word_idx.keys()):\n",
    "    # Look up the word embedding\n",
    "    vector = word_lookup.get(word, None)\n",
    "\n",
    "    # Record in matrix\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i + 1, :] = vector\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(f'There were {not_found} words without pre-trained embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "del vectors\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebashc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/sebashc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Normalize and convert nan to 0\n",
    "embedding_matrix = embedding_matrix / \\\n",
    "    np.linalg.norm(embedding_matrix, axis=1).reshape((-1, 1))\n",
    "embedding_matrix = np.nan_to_num(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the model to be tuned is: an embedding layer, a masking, n possible LSTM layers, a final LSTM layer, a dense layer, a dropout and a final dense layer. In this model the LSTM cells, the LSTM layers, the optimizer, the dropout rate, the neurons in the dense layers and the learning rate can be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_cells=64, lstm_layers=1, optimizer=\"adam\",\n",
    "                neurons=128, dropout_rate=0.5, learning_rate=0.1):\n",
    "    \n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    if optimizer == \"rmsprop\":\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(\n",
    "            Embedding(\n",
    "                input_dim=num_words,\n",
    "                output_dim=embedding_matrix.shape[1],\n",
    "                weights=[embedding_matrix],\n",
    "                trainable=False,\n",
    "                mask_zero=True))\n",
    "    \n",
    "    model.add(Masking())\n",
    "    \n",
    "    if lstm_layers > 1:\n",
    "        for i in range(0,lstm_layers-1):\n",
    "            model.add(\n",
    "                LSTM(\n",
    "                    units=lstm_cells,\n",
    "                    return_sequences=True,\n",
    "                    recurrent_dropout=dropout_rate))\n",
    "            \n",
    "    model.add(\n",
    "            LSTM(\n",
    "                units=lstm_cells,\n",
    "                return_sequences=False,\n",
    "                dropout=dropout_rate))\n",
    "    \n",
    "    model.add(Dense(units=neurons, activation='relu'))\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random search and the grid search algortihm are used for the hyper parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "#param_dist={\"lstm_cells\":sp_randint(64,100),\n",
    " #           \"epochs\":sp_randint(20,100),\n",
    "  #          \"lstm_layers\":sp_randint(1,2),\n",
    "   #         \"neurons\":sp_randint(64,128),\n",
    "    #        \"optimizer\":sp_randint(1,2),\n",
    "     #       \"learning_rate\":sp_randint(0.05,0.1),\n",
    "      #      \"dropout_rate\":sp_randint(0.2,0.5)}\n",
    "\n",
    "param_dist={\"optimizer\":[\"adam\",\"rmsprop\"],\n",
    "            \"learning_rate\":[0.001,0.01],\n",
    "            \"lstm_layers\":[1,2,3],\n",
    "            \"lstm_cells\":[64,128,200],\n",
    "            \"neurons\":[64,128,200],\n",
    "            \"dropout_rate\":[0.1,0.2,0.5],\n",
    "            \"epochs\":[10,25,50],\n",
    "           \"batch_size\":[800,1000,2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebashc/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/50\n",
      "6832/6832 [==============================] - 4s 517us/step - loss: 1.0810 - accuracy: 0.5271 - val_loss: 1.0315 - val_accuracy: 0.6407\n",
      "Epoch 2/50\n",
      "6832/6832 [==============================] - 2s 258us/step - loss: 1.0109 - accuracy: 0.6200 - val_loss: 0.9286 - val_accuracy: 0.6407\n",
      "Epoch 3/50\n",
      "6832/6832 [==============================] - 2s 264us/step - loss: 0.9070 - accuracy: 0.6199 - val_loss: 0.8379 - val_accuracy: 0.6407\n",
      "Epoch 4/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.8987 - accuracy: 0.6199 - val_loss: 0.8493 - val_accuracy: 0.6407\n",
      "Epoch 5/50\n",
      "6832/6832 [==============================] - 2s 254us/step - loss: 0.8811 - accuracy: 0.6199 - val_loss: 0.8371 - val_accuracy: 0.6407\n",
      "Epoch 6/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.8721 - accuracy: 0.6200 - val_loss: 0.8505 - val_accuracy: 0.6407\n",
      "Epoch 7/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.8738 - accuracy: 0.6199 - val_loss: 0.8348 - val_accuracy: 0.6407\n",
      "Epoch 8/50\n",
      "6832/6832 [==============================] - 2s 251us/step - loss: 0.8587 - accuracy: 0.6200 - val_loss: 0.8169 - val_accuracy: 0.6409\n",
      "Epoch 9/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.8516 - accuracy: 0.6202 - val_loss: 0.8098 - val_accuracy: 0.6407\n",
      "Epoch 10/50\n",
      "6832/6832 [==============================] - 2s 250us/step - loss: 0.8442 - accuracy: 0.6206 - val_loss: 0.8004 - val_accuracy: 0.6416\n",
      "Epoch 11/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.8317 - accuracy: 0.6231 - val_loss: 0.7913 - val_accuracy: 0.6539\n",
      "Epoch 12/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.8184 - accuracy: 0.6363 - val_loss: 0.7706 - val_accuracy: 0.6651\n",
      "Epoch 13/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.8046 - accuracy: 0.6487 - val_loss: 0.7531 - val_accuracy: 0.6835\n",
      "Epoch 14/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.7875 - accuracy: 0.6768 - val_loss: 0.7323 - val_accuracy: 0.7106\n",
      "Epoch 15/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.7744 - accuracy: 0.6906 - val_loss: 0.7252 - val_accuracy: 0.7391\n",
      "Epoch 16/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.7617 - accuracy: 0.7068 - val_loss: 0.6984 - val_accuracy: 0.7386\n",
      "Epoch 17/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.7436 - accuracy: 0.7080 - val_loss: 0.6800 - val_accuracy: 0.7486\n",
      "Epoch 18/50\n",
      "6832/6832 [==============================] - 2s 246us/step - loss: 0.7259 - accuracy: 0.7156 - val_loss: 0.6622 - val_accuracy: 0.7511\n",
      "Epoch 19/50\n",
      "6832/6832 [==============================] - 2s 246us/step - loss: 0.7070 - accuracy: 0.7194 - val_loss: 0.6489 - val_accuracy: 0.7550\n",
      "Epoch 20/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.7003 - accuracy: 0.7203 - val_loss: 0.6358 - val_accuracy: 0.7573\n",
      "Epoch 21/50\n",
      "6832/6832 [==============================] - 2s 246us/step - loss: 0.6839 - accuracy: 0.7228 - val_loss: 0.6269 - val_accuracy: 0.7559\n",
      "Epoch 22/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6793 - accuracy: 0.7250 - val_loss: 0.6196 - val_accuracy: 0.7577\n",
      "Epoch 23/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6729 - accuracy: 0.7209 - val_loss: 0.6164 - val_accuracy: 0.7591\n",
      "Epoch 24/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6644 - accuracy: 0.7267 - val_loss: 0.6147 - val_accuracy: 0.7566\n",
      "Epoch 25/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6643 - accuracy: 0.7291 - val_loss: 0.6081 - val_accuracy: 0.7607\n",
      "Epoch 26/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6585 - accuracy: 0.7339 - val_loss: 0.6044 - val_accuracy: 0.7612\n",
      "Epoch 27/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.6496 - accuracy: 0.7386 - val_loss: 0.6043 - val_accuracy: 0.7655\n",
      "Epoch 28/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6472 - accuracy: 0.7359 - val_loss: 0.6027 - val_accuracy: 0.7561\n",
      "Epoch 29/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6481 - accuracy: 0.7343 - val_loss: 0.5944 - val_accuracy: 0.7650\n",
      "Epoch 30/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6370 - accuracy: 0.7392 - val_loss: 0.5917 - val_accuracy: 0.7628\n",
      "Epoch 31/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6395 - accuracy: 0.7345 - val_loss: 0.5937 - val_accuracy: 0.7623\n",
      "Epoch 32/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6436 - accuracy: 0.7346 - val_loss: 0.5871 - val_accuracy: 0.7625\n",
      "Epoch 33/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6356 - accuracy: 0.7399 - val_loss: 0.5897 - val_accuracy: 0.7639\n",
      "Epoch 34/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6342 - accuracy: 0.7436 - val_loss: 0.5870 - val_accuracy: 0.7612\n",
      "Epoch 35/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6292 - accuracy: 0.7405 - val_loss: 0.5894 - val_accuracy: 0.7664\n",
      "Epoch 36/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6247 - accuracy: 0.7415 - val_loss: 0.5956 - val_accuracy: 0.7609\n",
      "Epoch 37/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6341 - accuracy: 0.7408 - val_loss: 0.5970 - val_accuracy: 0.7643\n",
      "Epoch 38/50\n",
      "6832/6832 [==============================] - 2s 246us/step - loss: 0.6359 - accuracy: 0.7368 - val_loss: 0.5888 - val_accuracy: 0.7648\n",
      "Epoch 39/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6255 - accuracy: 0.7444 - val_loss: 0.5967 - val_accuracy: 0.7575\n",
      "Epoch 40/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6378 - accuracy: 0.7370 - val_loss: 0.5840 - val_accuracy: 0.7671\n",
      "Epoch 41/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6269 - accuracy: 0.7428 - val_loss: 0.5802 - val_accuracy: 0.7643\n",
      "Epoch 42/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6223 - accuracy: 0.7428 - val_loss: 0.5779 - val_accuracy: 0.7696\n",
      "Epoch 43/50\n",
      "6832/6832 [==============================] - 2s 246us/step - loss: 0.6167 - accuracy: 0.7493 - val_loss: 0.5779 - val_accuracy: 0.7616\n",
      "Epoch 44/50\n",
      "6832/6832 [==============================] - 2s 246us/step - loss: 0.6239 - accuracy: 0.7462 - val_loss: 0.5774 - val_accuracy: 0.7675\n",
      "Epoch 45/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6221 - accuracy: 0.7450 - val_loss: 0.5768 - val_accuracy: 0.7664\n",
      "Epoch 46/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6172 - accuracy: 0.7452 - val_loss: 0.5800 - val_accuracy: 0.7625\n",
      "Epoch 47/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6164 - accuracy: 0.7431 - val_loss: 0.5785 - val_accuracy: 0.7680\n",
      "Epoch 48/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6114 - accuracy: 0.7471 - val_loss: 0.5755 - val_accuracy: 0.7664\n",
      "Epoch 49/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6126 - accuracy: 0.7450 - val_loss: 0.5768 - val_accuracy: 0.7641\n",
      "Epoch 50/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6097 - accuracy: 0.7503 - val_loss: 0.5756 - val_accuracy: 0.7728\n",
      "3416/3416 [==============================] - 0s 77us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/50\n",
      "6832/6832 [==============================] - 3s 486us/step - loss: 1.0569 - accuracy: 0.5973 - val_loss: 0.9955 - val_accuracy: 0.6407\n",
      "Epoch 2/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.9719 - accuracy: 0.6270 - val_loss: 0.8887 - val_accuracy: 0.6407\n",
      "Epoch 3/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.8836 - accuracy: 0.6273 - val_loss: 0.8547 - val_accuracy: 0.6407\n",
      "Epoch 4/50\n",
      "6832/6832 [==============================] - 2s 254us/step - loss: 0.8896 - accuracy: 0.6273 - val_loss: 0.8419 - val_accuracy: 0.6407\n",
      "Epoch 5/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.8616 - accuracy: 0.6272 - val_loss: 0.8425 - val_accuracy: 0.6407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.8640 - accuracy: 0.6273 - val_loss: 0.8431 - val_accuracy: 0.6407\n",
      "Epoch 7/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.8557 - accuracy: 0.6275 - val_loss: 0.8233 - val_accuracy: 0.6407\n",
      "Epoch 8/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.8425 - accuracy: 0.6275 - val_loss: 0.8150 - val_accuracy: 0.6407\n",
      "Epoch 9/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.8341 - accuracy: 0.6287 - val_loss: 0.8020 - val_accuracy: 0.6421\n",
      "Epoch 10/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.8207 - accuracy: 0.6314 - val_loss: 0.7928 - val_accuracy: 0.6469\n",
      "Epoch 11/50\n",
      "6832/6832 [==============================] - 2s 257us/step - loss: 0.8079 - accuracy: 0.6420 - val_loss: 0.7723 - val_accuracy: 0.6621\n",
      "Epoch 12/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.7906 - accuracy: 0.6538 - val_loss: 0.7551 - val_accuracy: 0.6851\n",
      "Epoch 13/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.7744 - accuracy: 0.6834 - val_loss: 0.7372 - val_accuracy: 0.7113\n",
      "Epoch 14/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.7599 - accuracy: 0.7024 - val_loss: 0.7230 - val_accuracy: 0.7243\n",
      "Epoch 15/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.7434 - accuracy: 0.7134 - val_loss: 0.7064 - val_accuracy: 0.7322\n",
      "Epoch 16/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.7279 - accuracy: 0.7172 - val_loss: 0.6934 - val_accuracy: 0.7384\n",
      "Epoch 17/50\n",
      "6832/6832 [==============================] - 2s 274us/step - loss: 0.7100 - accuracy: 0.7223 - val_loss: 0.6686 - val_accuracy: 0.7420\n",
      "Epoch 18/50\n",
      "6832/6832 [==============================] - 2s 255us/step - loss: 0.6917 - accuracy: 0.7272 - val_loss: 0.6552 - val_accuracy: 0.7450\n",
      "Epoch 19/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6809 - accuracy: 0.7314 - val_loss: 0.6486 - val_accuracy: 0.7507\n",
      "Epoch 20/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6741 - accuracy: 0.7269 - val_loss: 0.6332 - val_accuracy: 0.7514\n",
      "Epoch 21/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6553 - accuracy: 0.7398 - val_loss: 0.6298 - val_accuracy: 0.7534\n",
      "Epoch 22/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6567 - accuracy: 0.7376 - val_loss: 0.6180 - val_accuracy: 0.7580\n",
      "Epoch 23/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6498 - accuracy: 0.7383 - val_loss: 0.6145 - val_accuracy: 0.7564\n",
      "Epoch 24/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6454 - accuracy: 0.7405 - val_loss: 0.6089 - val_accuracy: 0.7616\n",
      "Epoch 25/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6368 - accuracy: 0.7437 - val_loss: 0.6048 - val_accuracy: 0.7591\n",
      "Epoch 26/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6300 - accuracy: 0.7462 - val_loss: 0.5992 - val_accuracy: 0.7632\n",
      "Epoch 27/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6272 - accuracy: 0.7450 - val_loss: 0.5982 - val_accuracy: 0.7628\n",
      "Epoch 28/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6209 - accuracy: 0.7465 - val_loss: 0.5991 - val_accuracy: 0.7593\n",
      "Epoch 29/50\n",
      "6832/6832 [==============================] - 2s 254us/step - loss: 0.6271 - accuracy: 0.7487 - val_loss: 0.5942 - val_accuracy: 0.7653\n",
      "Epoch 30/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.6224 - accuracy: 0.7513 - val_loss: 0.5898 - val_accuracy: 0.7621\n",
      "Epoch 31/50\n",
      "6832/6832 [==============================] - 2s 255us/step - loss: 0.6163 - accuracy: 0.7490 - val_loss: 0.5921 - val_accuracy: 0.7609\n",
      "Epoch 32/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.6171 - accuracy: 0.7516 - val_loss: 0.5877 - val_accuracy: 0.7664\n",
      "Epoch 33/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6153 - accuracy: 0.7487 - val_loss: 0.5858 - val_accuracy: 0.7643\n",
      "Epoch 34/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6081 - accuracy: 0.7545 - val_loss: 0.5846 - val_accuracy: 0.7653\n",
      "Epoch 35/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6054 - accuracy: 0.7499 - val_loss: 0.5840 - val_accuracy: 0.7650\n",
      "Epoch 36/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.6061 - accuracy: 0.7531 - val_loss: 0.5818 - val_accuracy: 0.7643\n",
      "Epoch 37/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6036 - accuracy: 0.7542 - val_loss: 0.5806 - val_accuracy: 0.7643\n",
      "Epoch 38/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.6007 - accuracy: 0.7569 - val_loss: 0.5839 - val_accuracy: 0.7648\n",
      "Epoch 39/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.6077 - accuracy: 0.7547 - val_loss: 0.5855 - val_accuracy: 0.7639\n",
      "Epoch 40/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.6049 - accuracy: 0.7545 - val_loss: 0.5827 - val_accuracy: 0.7689\n",
      "Epoch 41/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.6057 - accuracy: 0.7488 - val_loss: 0.5808 - val_accuracy: 0.7655\n",
      "Epoch 42/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.5985 - accuracy: 0.7566 - val_loss: 0.5759 - val_accuracy: 0.7696\n",
      "Epoch 43/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.6016 - accuracy: 0.7586 - val_loss: 0.5755 - val_accuracy: 0.7680\n",
      "Epoch 44/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.5974 - accuracy: 0.7532 - val_loss: 0.5806 - val_accuracy: 0.7637\n",
      "Epoch 45/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.5970 - accuracy: 0.7550 - val_loss: 0.5809 - val_accuracy: 0.7709\n",
      "Epoch 46/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.5921 - accuracy: 0.7588 - val_loss: 0.5790 - val_accuracy: 0.7616\n",
      "Epoch 47/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.5948 - accuracy: 0.7575 - val_loss: 0.5734 - val_accuracy: 0.7673\n",
      "Epoch 48/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.5879 - accuracy: 0.7614 - val_loss: 0.5735 - val_accuracy: 0.7675\n",
      "Epoch 49/50\n",
      "6832/6832 [==============================] - 2s 253us/step - loss: 0.5889 - accuracy: 0.7616 - val_loss: 0.5722 - val_accuracy: 0.7678\n",
      "Epoch 50/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.5890 - accuracy: 0.7594 - val_loss: 0.5712 - val_accuracy: 0.7675\n",
      "3416/3416 [==============================] - 0s 77us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/50\n",
      "6832/6832 [==============================] - 3s 490us/step - loss: 1.0767 - accuracy: 0.5142 - val_loss: 1.0136 - val_accuracy: 0.6407\n",
      "Epoch 2/50\n",
      "6832/6832 [==============================] - 2s 252us/step - loss: 0.9908 - accuracy: 0.6164 - val_loss: 0.8974 - val_accuracy: 0.6407\n",
      "Epoch 3/50\n",
      "6832/6832 [==============================] - 2s 250us/step - loss: 0.8946 - accuracy: 0.6164 - val_loss: 0.8487 - val_accuracy: 0.6407\n",
      "Epoch 4/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.9001 - accuracy: 0.6164 - val_loss: 0.8411 - val_accuracy: 0.6407\n",
      "Epoch 5/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.8760 - accuracy: 0.6164 - val_loss: 0.8414 - val_accuracy: 0.6407\n",
      "Epoch 6/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.8725 - accuracy: 0.6164 - val_loss: 0.8438 - val_accuracy: 0.6407\n",
      "Epoch 7/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.8671 - accuracy: 0.6165 - val_loss: 0.8239 - val_accuracy: 0.6405\n",
      "Epoch 8/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.8534 - accuracy: 0.6164 - val_loss: 0.8124 - val_accuracy: 0.6409\n",
      "Epoch 9/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.8463 - accuracy: 0.6169 - val_loss: 0.8007 - val_accuracy: 0.6439\n",
      "Epoch 10/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.8320 - accuracy: 0.6210 - val_loss: 0.7958 - val_accuracy: 0.6516\n",
      "Epoch 11/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.8213 - accuracy: 0.6304 - val_loss: 0.7727 - val_accuracy: 0.6617\n",
      "Epoch 12/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.8038 - accuracy: 0.6410 - val_loss: 0.7569 - val_accuracy: 0.6733\n",
      "Epoch 13/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.7918 - accuracy: 0.6606 - val_loss: 0.7429 - val_accuracy: 0.6913\n",
      "Epoch 14/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.7738 - accuracy: 0.6732 - val_loss: 0.7314 - val_accuracy: 0.7108\n",
      "Epoch 15/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.7617 - accuracy: 0.6986 - val_loss: 0.7125 - val_accuracy: 0.7281\n",
      "Epoch 16/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.7429 - accuracy: 0.7067 - val_loss: 0.6949 - val_accuracy: 0.7425\n",
      "Epoch 17/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.7223 - accuracy: 0.7162 - val_loss: 0.6751 - val_accuracy: 0.7502\n",
      "Epoch 18/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.7076 - accuracy: 0.7197 - val_loss: 0.6564 - val_accuracy: 0.7536\n",
      "Epoch 19/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6902 - accuracy: 0.7245 - val_loss: 0.6449 - val_accuracy: 0.7539\n",
      "Epoch 20/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6763 - accuracy: 0.7323 - val_loss: 0.6334 - val_accuracy: 0.7516\n",
      "Epoch 21/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6659 - accuracy: 0.7329 - val_loss: 0.6282 - val_accuracy: 0.7520\n",
      "Epoch 22/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6626 - accuracy: 0.7329 - val_loss: 0.6292 - val_accuracy: 0.7591\n",
      "Epoch 23/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6545 - accuracy: 0.7320 - val_loss: 0.6186 - val_accuracy: 0.7557\n",
      "Epoch 24/50\n",
      "6832/6832 [==============================] - 2s 251us/step - loss: 0.6458 - accuracy: 0.7317 - val_loss: 0.6241 - val_accuracy: 0.7516\n",
      "Epoch 25/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6453 - accuracy: 0.7377 - val_loss: 0.6115 - val_accuracy: 0.7577\n",
      "Epoch 26/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6386 - accuracy: 0.7424 - val_loss: 0.6050 - val_accuracy: 0.7559\n",
      "Epoch 27/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6337 - accuracy: 0.7430 - val_loss: 0.6018 - val_accuracy: 0.7605\n",
      "Epoch 28/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6304 - accuracy: 0.7431 - val_loss: 0.6008 - val_accuracy: 0.7630\n",
      "Epoch 29/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6257 - accuracy: 0.7463 - val_loss: 0.5964 - val_accuracy: 0.7602\n",
      "Epoch 30/50\n",
      "6832/6832 [==============================] - 2s 250us/step - loss: 0.6265 - accuracy: 0.7425 - val_loss: 0.5960 - val_accuracy: 0.7634\n",
      "Epoch 31/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6271 - accuracy: 0.7456 - val_loss: 0.5934 - val_accuracy: 0.7628\n",
      "Epoch 32/50\n",
      "6832/6832 [==============================] - 2s 261us/step - loss: 0.6193 - accuracy: 0.7443 - val_loss: 0.5965 - val_accuracy: 0.7573\n",
      "Epoch 33/50\n",
      "6832/6832 [==============================] - 2s 263us/step - loss: 0.6254 - accuracy: 0.7468 - val_loss: 0.5898 - val_accuracy: 0.7657\n",
      "Epoch 34/50\n",
      "6832/6832 [==============================] - 2s 251us/step - loss: 0.6121 - accuracy: 0.7532 - val_loss: 0.5887 - val_accuracy: 0.7641\n",
      "Epoch 35/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6123 - accuracy: 0.7477 - val_loss: 0.5903 - val_accuracy: 0.7616\n",
      "Epoch 36/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6138 - accuracy: 0.7480 - val_loss: 0.5988 - val_accuracy: 0.7621\n",
      "Epoch 37/50\n",
      "6832/6832 [==============================] - 2s 250us/step - loss: 0.6173 - accuracy: 0.7439 - val_loss: 0.5940 - val_accuracy: 0.7598\n",
      "Epoch 38/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6130 - accuracy: 0.7506 - val_loss: 0.5884 - val_accuracy: 0.7648\n",
      "Epoch 39/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6076 - accuracy: 0.7491 - val_loss: 0.5840 - val_accuracy: 0.7643\n",
      "Epoch 40/50\n",
      "6832/6832 [==============================] - 2s 250us/step - loss: 0.6101 - accuracy: 0.7569 - val_loss: 0.5853 - val_accuracy: 0.7634\n",
      "Epoch 41/50\n",
      "6832/6832 [==============================] - 2s 250us/step - loss: 0.6034 - accuracy: 0.7500 - val_loss: 0.5832 - val_accuracy: 0.7628\n",
      "Epoch 42/50\n",
      "6832/6832 [==============================] - 2s 254us/step - loss: 0.6070 - accuracy: 0.7515 - val_loss: 0.5808 - val_accuracy: 0.7671\n",
      "Epoch 43/50\n",
      "6832/6832 [==============================] - 2s 247us/step - loss: 0.6028 - accuracy: 0.7523 - val_loss: 0.5810 - val_accuracy: 0.7659\n",
      "Epoch 44/50\n",
      "6832/6832 [==============================] - 2s 251us/step - loss: 0.6038 - accuracy: 0.7503 - val_loss: 0.5810 - val_accuracy: 0.7666\n",
      "Epoch 45/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6023 - accuracy: 0.7545 - val_loss: 0.5795 - val_accuracy: 0.7646\n",
      "Epoch 46/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6017 - accuracy: 0.7518 - val_loss: 0.5837 - val_accuracy: 0.7612\n",
      "Epoch 47/50\n",
      "6832/6832 [==============================] - 2s 249us/step - loss: 0.6023 - accuracy: 0.7481 - val_loss: 0.5854 - val_accuracy: 0.7632\n",
      "Epoch 48/50\n",
      "6832/6832 [==============================] - 2s 250us/step - loss: 0.6012 - accuracy: 0.7564 - val_loss: 0.5823 - val_accuracy: 0.7655\n",
      "Epoch 49/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.6014 - accuracy: 0.7528 - val_loss: 0.5793 - val_accuracy: 0.7630\n",
      "Epoch 50/50\n",
      "6832/6832 [==============================] - 2s 248us/step - loss: 0.5956 - accuracy: 0.7518 - val_loss: 0.5801 - val_accuracy: 0.7655\n",
      "3416/3416 [==============================] - 0s 77us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 1.0721 - accuracy: 0.5347 - val_loss: 0.8837 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 690us/step - loss: 0.9604 - accuracy: 0.6197 - val_loss: 1.1429 - val_accuracy: 0.1967\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 693us/step - loss: 0.9575 - accuracy: 0.5629 - val_loss: 0.9146 - val_accuracy: 0.6407\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 697us/step - loss: 0.9579 - accuracy: 0.6155 - val_loss: 0.8531 - val_accuracy: 0.6407\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 5s 701us/step - loss: 0.9333 - accuracy: 0.6190 - val_loss: 0.9634 - val_accuracy: 0.6407\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 693us/step - loss: 0.9198 - accuracy: 0.6197 - val_loss: 0.8256 - val_accuracy: 0.6407\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.9730 - accuracy: 0.5681 - val_loss: 0.8203 - val_accuracy: 0.6407\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.8939 - accuracy: 0.5881 - val_loss: 0.9139 - val_accuracy: 0.6407\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 697us/step - loss: 0.8825 - accuracy: 0.6197 - val_loss: 0.8056 - val_accuracy: 0.6407\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 702us/step - loss: 0.8812 - accuracy: 0.5846 - val_loss: 0.7913 - val_accuracy: 0.6407\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.8393 - accuracy: 0.6240 - val_loss: 0.8011 - val_accuracy: 0.6004\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 697us/step - loss: 0.8152 - accuracy: 0.6355 - val_loss: 0.8055 - val_accuracy: 0.6646\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.8103 - accuracy: 0.6673 - val_loss: 0.8023 - val_accuracy: 0.6917\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 713us/step - loss: 0.7909 - accuracy: 0.6708 - val_loss: 0.8068 - val_accuracy: 0.6605\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 698us/step - loss: 0.7726 - accuracy: 0.6745 - val_loss: 0.6752 - val_accuracy: 0.7288\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.7381 - accuracy: 0.6975 - val_loss: 0.6812 - val_accuracy: 0.7222\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 719us/step - loss: 0.7413 - accuracy: 0.6966 - val_loss: 0.6750 - val_accuracy: 0.7450\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 707us/step - loss: 0.6878 - accuracy: 0.7302 - val_loss: 0.6544 - val_accuracy: 0.7425\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 697us/step - loss: 0.7090 - accuracy: 0.7143 - val_loss: 0.6680 - val_accuracy: 0.7311\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 693us/step - loss: 0.6849 - accuracy: 0.7275 - val_loss: 0.9197 - val_accuracy: 0.5952\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.7103 - accuracy: 0.7103 - val_loss: 0.6562 - val_accuracy: 0.7568\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.6858 - accuracy: 0.7323 - val_loss: 0.6063 - val_accuracy: 0.7582\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 692us/step - loss: 0.6441 - accuracy: 0.7389 - val_loss: 0.6119 - val_accuracy: 0.7668\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.6370 - accuracy: 0.7491 - val_loss: 0.6105 - val_accuracy: 0.7589\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.6477 - accuracy: 0.7384 - val_loss: 0.6034 - val_accuracy: 0.7698\n",
      "3416/3416 [==============================] - 1s 201us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 1.0856 - accuracy: 0.4622 - val_loss: 0.8647 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 691us/step - loss: 0.8959 - accuracy: 0.6272 - val_loss: 0.8418 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 689us/step - loss: 0.8973 - accuracy: 0.6268 - val_loss: 0.8467 - val_accuracy: 0.6412\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 692us/step - loss: 0.8792 - accuracy: 0.6309 - val_loss: 0.8311 - val_accuracy: 0.6444\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 5s 692us/step - loss: 0.8693 - accuracy: 0.6392 - val_loss: 0.8478 - val_accuracy: 0.6617\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.9025 - accuracy: 0.6292 - val_loss: 0.8677 - val_accuracy: 0.6441\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.8659 - accuracy: 0.6414 - val_loss: 0.8069 - val_accuracy: 0.6696\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.8427 - accuracy: 0.6612 - val_loss: 0.7711 - val_accuracy: 0.6979\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.8361 - accuracy: 0.6546 - val_loss: 0.8125 - val_accuracy: 0.6972\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.8072 - accuracy: 0.6790 - val_loss: 0.7375 - val_accuracy: 0.7056\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.7959 - accuracy: 0.6800 - val_loss: 0.7393 - val_accuracy: 0.7229\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.7792 - accuracy: 0.6945 - val_loss: 0.6959 - val_accuracy: 0.7149\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.7684 - accuracy: 0.7017 - val_loss: 0.7026 - val_accuracy: 0.7277\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 697us/step - loss: 0.7522 - accuracy: 0.7064 - val_loss: 0.7053 - val_accuracy: 0.7272\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 727us/step - loss: 0.7104 - accuracy: 0.7150 - val_loss: 0.9950 - val_accuracy: 0.6664\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.7362 - accuracy: 0.7172 - val_loss: 0.8144 - val_accuracy: 0.6906\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.6744 - accuracy: 0.7351 - val_loss: 0.6431 - val_accuracy: 0.7489\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.6899 - accuracy: 0.7210 - val_loss: 0.6618 - val_accuracy: 0.7486\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 693us/step - loss: 0.6837 - accuracy: 0.7327 - val_loss: 0.7243 - val_accuracy: 0.7081\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.6523 - accuracy: 0.7436 - val_loss: 0.6821 - val_accuracy: 0.7293\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 692us/step - loss: 0.6393 - accuracy: 0.7504 - val_loss: 0.6407 - val_accuracy: 0.7505\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.6475 - accuracy: 0.7424 - val_loss: 0.6425 - val_accuracy: 0.7543\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 698us/step - loss: 0.6390 - accuracy: 0.7463 - val_loss: 0.6594 - val_accuracy: 0.7386\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.6045 - accuracy: 0.7600 - val_loss: 0.5933 - val_accuracy: 0.7653\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 698us/step - loss: 0.6092 - accuracy: 0.7567 - val_loss: 0.5830 - val_accuracy: 0.7721\n",
      "3416/3416 [==============================] - 1s 203us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 1.1414 - accuracy: 0.5865 - val_loss: 0.8287 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 690us/step - loss: 0.9637 - accuracy: 0.6073 - val_loss: 0.8999 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 690us/step - loss: 0.9014 - accuracy: 0.6156 - val_loss: 0.8348 - val_accuracy: 0.6407\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 704us/step - loss: 0.8785 - accuracy: 0.6240 - val_loss: 0.7918 - val_accuracy: 0.6728\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 5s 692us/step - loss: 0.9475 - accuracy: 0.5717 - val_loss: 0.9709 - val_accuracy: 0.6409\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 693us/step - loss: 0.8698 - accuracy: 0.6251 - val_loss: 1.0674 - val_accuracy: 0.4226\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 693us/step - loss: 0.8861 - accuracy: 0.6104 - val_loss: 0.8152 - val_accuracy: 0.6872\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.9457 - accuracy: 0.5893 - val_loss: 0.7773 - val_accuracy: 0.6485\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.8622 - accuracy: 0.6130 - val_loss: 0.7492 - val_accuracy: 0.6605\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.8260 - accuracy: 0.6496 - val_loss: 0.7663 - val_accuracy: 0.6840\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 697us/step - loss: 0.7718 - accuracy: 0.6773 - val_loss: 0.9758 - val_accuracy: 0.5617\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 699us/step - loss: 0.7707 - accuracy: 0.6775 - val_loss: 0.6889 - val_accuracy: 0.7202\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 724us/step - loss: 0.7574 - accuracy: 0.6919 - val_loss: 0.6777 - val_accuracy: 0.7243\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.7109 - accuracy: 0.7083 - val_loss: 0.7620 - val_accuracy: 0.7318\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 698us/step - loss: 0.7159 - accuracy: 0.7182 - val_loss: 0.7765 - val_accuracy: 0.6910\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.7298 - accuracy: 0.7014 - val_loss: 0.6389 - val_accuracy: 0.7493\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 697us/step - loss: 0.6959 - accuracy: 0.7223 - val_loss: 0.6632 - val_accuracy: 0.7329\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.6871 - accuracy: 0.7256 - val_loss: 0.6251 - val_accuracy: 0.7534\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.6648 - accuracy: 0.7327 - val_loss: 0.7198 - val_accuracy: 0.7236\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.6515 - accuracy: 0.7376 - val_loss: 0.7640 - val_accuracy: 0.7090\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.6500 - accuracy: 0.7433 - val_loss: 0.5926 - val_accuracy: 0.7737\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 703us/step - loss: 0.6476 - accuracy: 0.7477 - val_loss: 0.5840 - val_accuracy: 0.7714\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 698us/step - loss: 0.6345 - accuracy: 0.7458 - val_loss: 0.6006 - val_accuracy: 0.7653\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.6312 - accuracy: 0.7425 - val_loss: 0.6301 - val_accuracy: 0.7564\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 695us/step - loss: 0.6124 - accuracy: 0.7545 - val_loss: 0.5801 - val_accuracy: 0.7735\n",
      "3416/3416 [==============================] - 1s 197us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 5s 769us/step - loss: 1.0255 - accuracy: 0.5176 - val_loss: 0.8592 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.9064 - accuracy: 0.6199 - val_loss: 0.8326 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.8948 - accuracy: 0.6199 - val_loss: 0.8437 - val_accuracy: 0.6407\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.8769 - accuracy: 0.6200 - val_loss: 0.8098 - val_accuracy: 0.6407\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.8605 - accuracy: 0.6212 - val_loss: 0.8005 - val_accuracy: 0.6409\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.8421 - accuracy: 0.6246 - val_loss: 0.7682 - val_accuracy: 0.6471\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.8235 - accuracy: 0.6388 - val_loss: 0.7466 - val_accuracy: 0.6696\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.8151 - accuracy: 0.6575 - val_loss: 0.7297 - val_accuracy: 0.6878\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.8063 - accuracy: 0.6645 - val_loss: 0.7195 - val_accuracy: 0.7170\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 4s 513us/step - loss: 0.7941 - accuracy: 0.6762 - val_loss: 0.6977 - val_accuracy: 0.7270\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7801 - accuracy: 0.6835 - val_loss: 0.6997 - val_accuracy: 0.7199\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7720 - accuracy: 0.6894 - val_loss: 0.6790 - val_accuracy: 0.7368\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7542 - accuracy: 0.6980 - val_loss: 0.6633 - val_accuracy: 0.7505\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 4s 513us/step - loss: 0.7582 - accuracy: 0.6948 - val_loss: 0.6734 - val_accuracy: 0.7398\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 4s 538us/step - loss: 0.7529 - accuracy: 0.6920 - val_loss: 0.6590 - val_accuracy: 0.7498\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7487 - accuracy: 0.6995 - val_loss: 0.6522 - val_accuracy: 0.7511\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7420 - accuracy: 0.6982 - val_loss: 0.6471 - val_accuracy: 0.7514\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7385 - accuracy: 0.6989 - val_loss: 0.6448 - val_accuracy: 0.7507\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7354 - accuracy: 0.7013 - val_loss: 0.6430 - val_accuracy: 0.7523\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7284 - accuracy: 0.7093 - val_loss: 0.6387 - val_accuracy: 0.7539\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7403 - accuracy: 0.6996 - val_loss: 0.6406 - val_accuracy: 0.7543\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7331 - accuracy: 0.7030 - val_loss: 0.6324 - val_accuracy: 0.7571\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7343 - accuracy: 0.7042 - val_loss: 0.6481 - val_accuracy: 0.7398\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7272 - accuracy: 0.7043 - val_loss: 0.6333 - val_accuracy: 0.7532\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7265 - accuracy: 0.7048 - val_loss: 0.6331 - val_accuracy: 0.7511\n",
      "3416/3416 [==============================] - 1s 149us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 5s 765us/step - loss: 1.0242 - accuracy: 0.5354 - val_loss: 0.8788 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.9222 - accuracy: 0.6275 - val_loss: 0.8398 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.8882 - accuracy: 0.6275 - val_loss: 0.8362 - val_accuracy: 0.6407\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.8693 - accuracy: 0.6278 - val_loss: 0.8116 - val_accuracy: 0.6407\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 4s 513us/step - loss: 0.8482 - accuracy: 0.6319 - val_loss: 0.7928 - val_accuracy: 0.6455\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.8262 - accuracy: 0.6426 - val_loss: 0.7674 - val_accuracy: 0.6658\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.8125 - accuracy: 0.6581 - val_loss: 0.7497 - val_accuracy: 0.6810\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7987 - accuracy: 0.6749 - val_loss: 0.7354 - val_accuracy: 0.6972\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7835 - accuracy: 0.6855 - val_loss: 0.7262 - val_accuracy: 0.7067\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7765 - accuracy: 0.6901 - val_loss: 0.7054 - val_accuracy: 0.7350\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7631 - accuracy: 0.6958 - val_loss: 0.6908 - val_accuracy: 0.7407\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7536 - accuracy: 0.7021 - val_loss: 0.6816 - val_accuracy: 0.7329\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7472 - accuracy: 0.6989 - val_loss: 0.6686 - val_accuracy: 0.7391\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7304 - accuracy: 0.7133 - val_loss: 0.6611 - val_accuracy: 0.7436\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7306 - accuracy: 0.7007 - val_loss: 0.6530 - val_accuracy: 0.7507\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7228 - accuracy: 0.7049 - val_loss: 0.6450 - val_accuracy: 0.7516\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7234 - accuracy: 0.7084 - val_loss: 0.6496 - val_accuracy: 0.7461\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7287 - accuracy: 0.7078 - val_loss: 0.6596 - val_accuracy: 0.7423\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7234 - accuracy: 0.7130 - val_loss: 0.6505 - val_accuracy: 0.7486\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 4s 514us/step - loss: 0.7191 - accuracy: 0.7083 - val_loss: 0.6410 - val_accuracy: 0.7534\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 4s 527us/step - loss: 0.7252 - accuracy: 0.7115 - val_loss: 0.6444 - val_accuracy: 0.7505\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 4s 516us/step - loss: 0.7037 - accuracy: 0.7203 - val_loss: 0.6301 - val_accuracy: 0.7516\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 4s 513us/step - loss: 0.7141 - accuracy: 0.7141 - val_loss: 0.6409 - val_accuracy: 0.7495\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7114 - accuracy: 0.7146 - val_loss: 0.6565 - val_accuracy: 0.7345\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.7097 - accuracy: 0.7122 - val_loss: 0.6497 - val_accuracy: 0.7407\n",
      "3416/3416 [==============================] - 1s 150us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 5s 769us/step - loss: 0.9935 - accuracy: 0.5969 - val_loss: 0.8390 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.9069 - accuracy: 0.6162 - val_loss: 0.8465 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 510us/step - loss: 0.8918 - accuracy: 0.6162 - val_loss: 0.8283 - val_accuracy: 0.6407\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 4s 513us/step - loss: 0.8693 - accuracy: 0.6164 - val_loss: 0.8034 - val_accuracy: 0.6407\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.8478 - accuracy: 0.6169 - val_loss: 0.7771 - val_accuracy: 0.6418\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.8262 - accuracy: 0.6268 - val_loss: 0.7562 - val_accuracy: 0.6680\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.8104 - accuracy: 0.6451 - val_loss: 0.7388 - val_accuracy: 0.6894\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 4s 513us/step - loss: 0.7927 - accuracy: 0.6629 - val_loss: 0.7243 - val_accuracy: 0.6990\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7904 - accuracy: 0.6661 - val_loss: 0.7059 - val_accuracy: 0.7122\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7706 - accuracy: 0.6777 - val_loss: 0.6846 - val_accuracy: 0.7352\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7586 - accuracy: 0.6901 - val_loss: 0.6701 - val_accuracy: 0.7509\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 4s 513us/step - loss: 0.7526 - accuracy: 0.6909 - val_loss: 0.6643 - val_accuracy: 0.7516\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7403 - accuracy: 0.6923 - val_loss: 0.6584 - val_accuracy: 0.7468\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7329 - accuracy: 0.7008 - val_loss: 0.6550 - val_accuracy: 0.7427\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 4s 515us/step - loss: 0.7363 - accuracy: 0.6996 - val_loss: 0.6590 - val_accuracy: 0.7432\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7448 - accuracy: 0.6973 - val_loss: 0.6538 - val_accuracy: 0.7473\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7332 - accuracy: 0.7014 - val_loss: 0.6448 - val_accuracy: 0.7520\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7290 - accuracy: 0.7001 - val_loss: 0.6470 - val_accuracy: 0.7434\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7239 - accuracy: 0.7035 - val_loss: 0.6514 - val_accuracy: 0.7441\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7259 - accuracy: 0.7013 - val_loss: 0.6453 - val_accuracy: 0.7450\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 4s 513us/step - loss: 0.7160 - accuracy: 0.7037 - val_loss: 0.6405 - val_accuracy: 0.7473\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 3s 512us/step - loss: 0.7162 - accuracy: 0.7013 - val_loss: 0.6467 - val_accuracy: 0.7457\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7240 - accuracy: 0.6992 - val_loss: 0.6374 - val_accuracy: 0.7470\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 4s 516us/step - loss: 0.7158 - accuracy: 0.7052 - val_loss: 0.6356 - val_accuracy: 0.7514\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 511us/step - loss: 0.7116 - accuracy: 0.7084 - val_loss: 0.6336 - val_accuracy: 0.7475\n",
      "3416/3416 [==============================] - 1s 151us/step\n",
      "Train on 10248 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "10248/10248 [==============================] - 10s 1ms/step - loss: 1.1747 - accuracy: 0.5847 - val_loss: 0.9063 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "10248/10248 [==============================] - 7s 637us/step - loss: 0.9233 - accuracy: 0.6192 - val_loss: 0.8591 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "10248/10248 [==============================] - 7s 645us/step - loss: 0.8875 - accuracy: 0.6231 - val_loss: 0.8584 - val_accuracy: 0.6612\n",
      "Epoch 4/25\n",
      "10248/10248 [==============================] - 7s 644us/step - loss: 0.8995 - accuracy: 0.6191 - val_loss: 0.7811 - val_accuracy: 0.6710\n",
      "Epoch 5/25\n",
      "10248/10248 [==============================] - 7s 643us/step - loss: 0.8991 - accuracy: 0.6028 - val_loss: 0.8819 - val_accuracy: 0.6407\n",
      "Epoch 6/25\n",
      "10248/10248 [==============================] - 7s 643us/step - loss: 0.8977 - accuracy: 0.6048 - val_loss: 0.8068 - val_accuracy: 0.6733\n",
      "Epoch 7/25\n",
      "10248/10248 [==============================] - 7s 645us/step - loss: 0.8148 - accuracy: 0.6672 - val_loss: 0.7178 - val_accuracy: 0.7129\n",
      "Epoch 8/25\n",
      "10248/10248 [==============================] - 7s 643us/step - loss: 0.8191 - accuracy: 0.6659 - val_loss: 0.7189 - val_accuracy: 0.7224\n",
      "Epoch 9/25\n",
      "10248/10248 [==============================] - 7s 644us/step - loss: 0.8112 - accuracy: 0.6711 - val_loss: 0.7492 - val_accuracy: 0.6721\n",
      "Epoch 10/25\n",
      "10248/10248 [==============================] - 7s 644us/step - loss: 0.7451 - accuracy: 0.7061 - val_loss: 0.8731 - val_accuracy: 0.5408\n",
      "Epoch 11/25\n",
      "10248/10248 [==============================] - 7s 643us/step - loss: 0.7785 - accuracy: 0.6829 - val_loss: 0.6565 - val_accuracy: 0.7402\n",
      "Epoch 12/25\n",
      "10248/10248 [==============================] - 7s 642us/step - loss: 0.7095 - accuracy: 0.7187 - val_loss: 0.6484 - val_accuracy: 0.7473\n",
      "Epoch 13/25\n",
      "10248/10248 [==============================] - 7s 644us/step - loss: 0.6963 - accuracy: 0.7266 - val_loss: 0.6060 - val_accuracy: 0.7657\n",
      "Epoch 14/25\n",
      "10248/10248 [==============================] - 7s 640us/step - loss: 0.6777 - accuracy: 0.7329 - val_loss: 0.6380 - val_accuracy: 0.7468\n",
      "Epoch 15/25\n",
      "10248/10248 [==============================] - 7s 642us/step - loss: 0.6533 - accuracy: 0.7415 - val_loss: 0.7679 - val_accuracy: 0.6815\n",
      "Epoch 16/25\n",
      "10248/10248 [==============================] - 7s 644us/step - loss: 0.6783 - accuracy: 0.7263 - val_loss: 0.7028 - val_accuracy: 0.7341\n",
      "Epoch 17/25\n",
      "10248/10248 [==============================] - 7s 643us/step - loss: 0.6402 - accuracy: 0.7454 - val_loss: 0.6154 - val_accuracy: 0.7719\n",
      "Epoch 18/25\n",
      "10248/10248 [==============================] - 7s 663us/step - loss: 0.6234 - accuracy: 0.7551 - val_loss: 0.5910 - val_accuracy: 0.7634\n",
      "Epoch 19/25\n",
      "10248/10248 [==============================] - 7s 645us/step - loss: 0.5955 - accuracy: 0.7616 - val_loss: 0.6281 - val_accuracy: 0.7694\n",
      "Epoch 20/25\n",
      "10248/10248 [==============================] - 7s 643us/step - loss: 0.6147 - accuracy: 0.7585 - val_loss: 0.5780 - val_accuracy: 0.7771\n",
      "Epoch 21/25\n",
      "10248/10248 [==============================] - 7s 642us/step - loss: 0.5941 - accuracy: 0.7623 - val_loss: 0.5689 - val_accuracy: 0.7719\n",
      "Epoch 22/25\n",
      "10248/10248 [==============================] - 7s 643us/step - loss: 0.5772 - accuracy: 0.7679 - val_loss: 0.5842 - val_accuracy: 0.7705\n",
      "Epoch 23/25\n",
      "10248/10248 [==============================] - 7s 645us/step - loss: 0.5867 - accuracy: 0.7670 - val_loss: 0.5659 - val_accuracy: 0.7801\n",
      "Epoch 24/25\n",
      "10248/10248 [==============================] - 7s 645us/step - loss: 0.5445 - accuracy: 0.7797 - val_loss: 0.5522 - val_accuracy: 0.7835\n",
      "Epoch 25/25\n",
      "10248/10248 [==============================] - 7s 647us/step - loss: 0.5768 - accuracy: 0.7738 - val_loss: 0.5468 - val_accuracy: 0.7873\n",
      "RandomizedSearchCV took 1135.88 seconds for 3 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.753 (std: 0.004)\n",
      "Parameters: {'optimizer': 'rmsprop', 'neurons': 64, 'lstm_layers': 3, 'lstm_cells': 64, 'learning_rate': 0.01, 'epochs': 25, 'dropout_rate': 0.2, 'batch_size': 800}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.749 (std: 0.011)\n",
      "Parameters: {'optimizer': 'adam', 'neurons': 200, 'lstm_layers': 1, 'lstm_cells': 64, 'learning_rate': 0.001, 'epochs': 50, 'dropout_rate': 0.1, 'batch_size': 2000}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.724 (std: 0.017)\n",
      "Parameters: {'optimizer': 'adam', 'neurons': 64, 'lstm_layers': 1, 'lstm_cells': 128, 'learning_rate': 0.001, 'epochs': 25, 'dropout_rate': 0.5, 'batch_size': 1000}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from time import time\n",
    "\n",
    "# funtion to present the result of the random and grid search\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "model=KerasClassifier(build_fn=create_model)\n",
    "\n",
    "n_iter_search = 3\n",
    "random_model=RandomizedSearchCV(estimator=model,param_distributions=param_dist,n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "history=random_model.fit(x_train,y_train,validation_data=(x_val,y_val))\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 484  152   58]\n",
      " [  81 2610  123]\n",
      " [  81  439  364]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72       646\n",
      "           1       0.93      0.82      0.87      3201\n",
      "           2       0.41      0.67      0.51       545\n",
      "\n",
      "    accuracy                           0.79      4392\n",
      "   macro avg       0.68      0.74      0.70      4392\n",
      "weighted avg       0.83      0.79      0.80      4392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "Y_pred = random_model.predict(x_test)\n",
    "\n",
    "CM = confusion_matrix(np.argmax(y_test, axis = 1), Y_pred)\n",
    "print(\"\\n\"+\"Confusion Matrix:\" + \"\\n\")\n",
    "print(CM)\n",
    "\n",
    "print(\"\\n\"+\"Classification Report\"+\"\\n\")\n",
    "print(classification_report(Y_pred,np.argmax(y_test, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the best model we add again the validation data to the training data and re-train the model to obtain better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new sets for training the model again\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10248/10248 [==============================] - 9s 836us/step - loss: 0.9941 - accuracy: 0.5441\n",
      "Epoch 2/25\n",
      "10248/10248 [==============================] - 6s 568us/step - loss: 0.9162 - accuracy: 0.6205\n",
      "Epoch 3/25\n",
      "10248/10248 [==============================] - 6s 564us/step - loss: 0.9277 - accuracy: 0.5862\n",
      "Epoch 4/25\n",
      "10248/10248 [==============================] - 6s 564us/step - loss: 0.8566 - accuracy: 0.6212\n",
      "Epoch 5/25\n",
      "10248/10248 [==============================] - 6s 564us/step - loss: 0.9263 - accuracy: 0.6227\n",
      "Epoch 6/25\n",
      "10248/10248 [==============================] - 6s 562us/step - loss: 0.8686 - accuracy: 0.6227\n",
      "Epoch 7/25\n",
      "10248/10248 [==============================] - 6s 572us/step - loss: 0.8324 - accuracy: 0.6512\n",
      "Epoch 8/25\n",
      "10248/10248 [==============================] - 6s 572us/step - loss: 0.8303 - accuracy: 0.6293\n",
      "Epoch 9/25\n",
      "10248/10248 [==============================] - 6s 572us/step - loss: 0.7718 - accuracy: 0.6759\n",
      "Epoch 10/25\n",
      "10248/10248 [==============================] - 6s 572us/step - loss: 0.7486 - accuracy: 0.6839\n",
      "Epoch 11/25\n",
      "10248/10248 [==============================] - 6s 572us/step - loss: 0.7106 - accuracy: 0.7043\n",
      "Epoch 12/25\n",
      "10248/10248 [==============================] - 6s 572us/step - loss: 0.6911 - accuracy: 0.7291\n",
      "Epoch 13/25\n",
      "10248/10248 [==============================] - 6s 574us/step - loss: 0.6686 - accuracy: 0.7347\n",
      "Epoch 14/25\n",
      "10248/10248 [==============================] - 6s 571us/step - loss: 0.6697 - accuracy: 0.7269\n",
      "Epoch 15/25\n",
      "10248/10248 [==============================] - 6s 572us/step - loss: 0.6484 - accuracy: 0.7399\n",
      "Epoch 16/25\n",
      "10248/10248 [==============================] - 6s 576us/step - loss: 0.6248 - accuracy: 0.7524\n",
      "Epoch 17/25\n",
      "10248/10248 [==============================] - 6s 598us/step - loss: 0.6158 - accuracy: 0.7548\n",
      "Epoch 18/25\n",
      "10248/10248 [==============================] - 6s 601us/step - loss: 0.6166 - accuracy: 0.7467\n",
      "Epoch 19/25\n",
      "10248/10248 [==============================] - 6s 580us/step - loss: 0.5890 - accuracy: 0.7608\n",
      "Epoch 20/25\n",
      "10248/10248 [==============================] - 6s 578us/step - loss: 0.5879 - accuracy: 0.7663\n",
      "Epoch 21/25\n",
      "10248/10248 [==============================] - 6s 608us/step - loss: 0.5976 - accuracy: 0.7594\n",
      "Epoch 22/25\n",
      "10248/10248 [==============================] - 6s 591us/step - loss: 0.5672 - accuracy: 0.7722\n",
      "Epoch 23/25\n",
      "10248/10248 [==============================] - 7s 642us/step - loss: 0.5550 - accuracy: 0.7795\n",
      "Epoch 24/25\n",
      "10248/10248 [==============================] - 6s 575us/step - loss: 0.5502 - accuracy: 0.7850\n",
      "Epoch 25/25\n",
      "10248/10248 [==============================] - 6s 574us/step - loss: 0.5505 - accuracy: 0.7775\n",
      "The model took 155.83 seconds with optimal hyperparamenters.\n"
     ]
    }
   ],
   "source": [
    "# creating model with the optimal hyperparameters\n",
    "\n",
    "model=create_model(optimizer='rmsprop',neurons=64,lstm_layers=3,lstm_cells=64,learning_rate=0.01,dropout_rate=0.2)\n",
    "\n",
    "start = time()\n",
    "history=model.fit(x_train2,y_train2, epochs=25, batch_size=800)\n",
    "print(\"The model took %.2f seconds with optimal hyperparamenters.\" %(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 484  152   58]\n",
      " [  81 2610  123]\n",
      " [  81  439  364]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72       646\n",
      "           1       0.93      0.82      0.87      3201\n",
      "           2       0.41      0.67      0.51       545\n",
      "\n",
      "    accuracy                           0.79      4392\n",
      "   macro avg       0.68      0.74      0.70      4392\n",
      "weighted avg       0.83      0.79      0.80      4392\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary statistics\n",
    "\n",
    "Y_pred = random_model.predict(x_test2)\n",
    "\n",
    "CM = confusion_matrix(np.argmax(y_test2, axis = 1), Y_pred)\n",
    "print(\"\\n\"+\"Confusion Matrix:\" + \"\\n\")\n",
    "print(CM)\n",
    "\n",
    "print(\"\\n\"+\"Classification Report\"+\"\\n\")\n",
    "print(classification_report(Y_pred,np.argmax(y_test2, axis = 1)))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the confusion matrix an the classification repot we can say that the model behaves well for the three tweet sentiment, with a little bias for the negative sentiments.\n",
    "\n",
    "On the othe hand, the accuracy and the loss graphs give evidence that a better training can be done and we can expect better results. For example, more epochs or a smaller batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disctionary of parameters for the grid search contains less options that the random search due to a lack in the computational capacity. When more parameters were added, the PC got stuck.\n",
    "\n",
    "A better Grid can be made in order to pursue better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from time import time\n",
    "\n",
    "param_dist={\"optimizer\":[\"adam\"],\n",
    "            \"learning_rate\":[0.01],\n",
    "            \"lstm_layers\":[2,3],\n",
    "            \"lstm_cells\":[64],\n",
    "            \"neurons\":[64],\n",
    "            \"dropout_rate\":[0.2,0.5],\n",
    "            \"epochs\":[25],\n",
    "           \"batch_size\":[1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebashc/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sebashc/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/sebashc/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 6s 838us/step - loss: 0.9559 - accuracy: 0.5607 - val_loss: 0.8460 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 455us/step - loss: 0.8699 - accuracy: 0.6199 - val_loss: 0.7738 - val_accuracy: 0.6434\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 474us/step - loss: 0.8445 - accuracy: 0.6194 - val_loss: 0.8028 - val_accuracy: 0.6771\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 3s 480us/step - loss: 0.8004 - accuracy: 0.6708 - val_loss: 0.7068 - val_accuracy: 0.7122\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.7550 - accuracy: 0.6897 - val_loss: 0.6734 - val_accuracy: 0.7268\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.7194 - accuracy: 0.6996 - val_loss: 0.6424 - val_accuracy: 0.7432\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.6829 - accuracy: 0.7225 - val_loss: 0.6228 - val_accuracy: 0.7509\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.6627 - accuracy: 0.7323 - val_loss: 0.5947 - val_accuracy: 0.7614\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.6353 - accuracy: 0.7427 - val_loss: 0.5867 - val_accuracy: 0.7584\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.6179 - accuracy: 0.7494 - val_loss: 0.5920 - val_accuracy: 0.7632\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5995 - accuracy: 0.7582 - val_loss: 0.5675 - val_accuracy: 0.7705\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.5805 - accuracy: 0.7642 - val_loss: 0.5570 - val_accuracy: 0.7785\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5721 - accuracy: 0.7701 - val_loss: 0.5913 - val_accuracy: 0.7602\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5619 - accuracy: 0.7709 - val_loss: 0.5486 - val_accuracy: 0.7791\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.5461 - accuracy: 0.7791 - val_loss: 0.5630 - val_accuracy: 0.7707\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.5440 - accuracy: 0.7806 - val_loss: 0.5572 - val_accuracy: 0.7728\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.5318 - accuracy: 0.7796 - val_loss: 0.5429 - val_accuracy: 0.7837\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5368 - accuracy: 0.7847 - val_loss: 0.5707 - val_accuracy: 0.7662\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5393 - accuracy: 0.7768 - val_loss: 0.5621 - val_accuracy: 0.7796\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.5191 - accuracy: 0.7888 - val_loss: 0.5402 - val_accuracy: 0.7853\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5221 - accuracy: 0.7885 - val_loss: 0.5316 - val_accuracy: 0.7903\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.4959 - accuracy: 0.7987 - val_loss: 0.5445 - val_accuracy: 0.7867\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.4801 - accuracy: 0.8049 - val_loss: 0.5322 - val_accuracy: 0.7928\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.4670 - accuracy: 0.8062 - val_loss: 0.5486 - val_accuracy: 0.7853\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.4632 - accuracy: 0.8137 - val_loss: 0.5579 - val_accuracy: 0.7830\n",
      "3416/3416 [==============================] - 0s 141us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 6s 823us/step - loss: 0.9803 - accuracy: 0.5622 - val_loss: 0.8432 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.8693 - accuracy: 0.6270 - val_loss: 0.8369 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.8302 - accuracy: 0.6273 - val_loss: 0.7647 - val_accuracy: 0.6446\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.7888 - accuracy: 0.6531 - val_loss: 0.7166 - val_accuracy: 0.7038\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.7378 - accuracy: 0.6932 - val_loss: 0.6918 - val_accuracy: 0.7240\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 454us/step - loss: 0.6942 - accuracy: 0.7207 - val_loss: 0.6378 - val_accuracy: 0.7493\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.6499 - accuracy: 0.7421 - val_loss: 0.6079 - val_accuracy: 0.7584\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 3s 454us/step - loss: 0.6240 - accuracy: 0.7542 - val_loss: 0.6001 - val_accuracy: 0.7561\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.6028 - accuracy: 0.7588 - val_loss: 0.5693 - val_accuracy: 0.7730\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.5905 - accuracy: 0.7636 - val_loss: 0.5619 - val_accuracy: 0.7732\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 475us/step - loss: 0.5713 - accuracy: 0.7703 - val_loss: 0.5784 - val_accuracy: 0.7666\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.5683 - accuracy: 0.7722 - val_loss: 0.5568 - val_accuracy: 0.7771\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.5539 - accuracy: 0.7796 - val_loss: 0.5594 - val_accuracy: 0.7794\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5496 - accuracy: 0.7796 - val_loss: 0.5658 - val_accuracy: 0.7755\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5379 - accuracy: 0.7816 - val_loss: 0.5537 - val_accuracy: 0.7730\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.5304 - accuracy: 0.7876 - val_loss: 0.5416 - val_accuracy: 0.7830\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 455us/step - loss: 0.5203 - accuracy: 0.7936 - val_loss: 0.5407 - val_accuracy: 0.7871\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 454us/step - loss: 0.5064 - accuracy: 0.7983 - val_loss: 0.5379 - val_accuracy: 0.7862\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.5116 - accuracy: 0.7949 - val_loss: 0.5849 - val_accuracy: 0.7753\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 3s 453us/step - loss: 0.5077 - accuracy: 0.7996 - val_loss: 0.5373 - val_accuracy: 0.7848\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.4923 - accuracy: 0.8023 - val_loss: 0.5507 - val_accuracy: 0.7869\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 3s 493us/step - loss: 0.4960 - accuracy: 0.8005 - val_loss: 0.5754 - val_accuracy: 0.7785\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 3s 461us/step - loss: 0.4877 - accuracy: 0.8031 - val_loss: 0.5430 - val_accuracy: 0.7898\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 3s 463us/step - loss: 0.4655 - accuracy: 0.8173 - val_loss: 0.5862 - val_accuracy: 0.7885\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 463us/step - loss: 0.4812 - accuracy: 0.8020 - val_loss: 0.5511 - val_accuracy: 0.7823\n",
      "3416/3416 [==============================] - 0s 139us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 6s 833us/step - loss: 0.9461 - accuracy: 0.5897 - val_loss: 0.8615 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.8656 - accuracy: 0.6164 - val_loss: 0.7748 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.7949 - accuracy: 0.6420 - val_loss: 0.7074 - val_accuracy: 0.7252\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.7267 - accuracy: 0.7016 - val_loss: 0.6568 - val_accuracy: 0.7409\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.6946 - accuracy: 0.7117 - val_loss: 0.6283 - val_accuracy: 0.7505\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.6557 - accuracy: 0.7342 - val_loss: 0.6242 - val_accuracy: 0.7505\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 445us/step - loss: 0.6280 - accuracy: 0.7471 - val_loss: 0.5842 - val_accuracy: 0.7657\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.6255 - accuracy: 0.7513 - val_loss: 0.5897 - val_accuracy: 0.7659\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.5994 - accuracy: 0.7626 - val_loss: 0.5748 - val_accuracy: 0.7668\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5892 - accuracy: 0.7581 - val_loss: 0.5901 - val_accuracy: 0.7659\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5730 - accuracy: 0.7649 - val_loss: 0.5691 - val_accuracy: 0.7712\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5571 - accuracy: 0.7739 - val_loss: 0.5699 - val_accuracy: 0.7655\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5590 - accuracy: 0.7705 - val_loss: 0.5497 - val_accuracy: 0.7794\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.5418 - accuracy: 0.7799 - val_loss: 0.5526 - val_accuracy: 0.7798\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.5302 - accuracy: 0.7850 - val_loss: 0.5428 - val_accuracy: 0.7821\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.5221 - accuracy: 0.7838 - val_loss: 0.5619 - val_accuracy: 0.7823\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.5313 - accuracy: 0.7850 - val_loss: 0.5591 - val_accuracy: 0.7691\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.5192 - accuracy: 0.7919 - val_loss: 0.5441 - val_accuracy: 0.7746\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.5058 - accuracy: 0.7936 - val_loss: 0.5449 - val_accuracy: 0.7803\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.4916 - accuracy: 0.7980 - val_loss: 0.5350 - val_accuracy: 0.7857\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.4773 - accuracy: 0.8043 - val_loss: 0.5366 - val_accuracy: 0.7871\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.4651 - accuracy: 0.8100 - val_loss: 0.5410 - val_accuracy: 0.7855\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 3s 479us/step - loss: 0.4578 - accuracy: 0.8137 - val_loss: 0.5361 - val_accuracy: 0.7926\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.4619 - accuracy: 0.8138 - val_loss: 0.5579 - val_accuracy: 0.7864\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.4525 - accuracy: 0.8162 - val_loss: 0.5670 - val_accuracy: 0.7794\n",
      "3416/3416 [==============================] - 0s 138us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 0.9533 - accuracy: 0.5697 - val_loss: 0.8532 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.8746 - accuracy: 0.6197 - val_loss: 0.7921 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.8331 - accuracy: 0.6268 - val_loss: 0.7445 - val_accuracy: 0.6826\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.7794 - accuracy: 0.6631 - val_loss: 0.6941 - val_accuracy: 0.7188\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.7336 - accuracy: 0.7010 - val_loss: 0.6813 - val_accuracy: 0.7156\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.7017 - accuracy: 0.7172 - val_loss: 0.6302 - val_accuracy: 0.7495\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 662us/step - loss: 0.6664 - accuracy: 0.7295 - val_loss: 0.6329 - val_accuracy: 0.7391\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.6487 - accuracy: 0.7365 - val_loss: 0.5973 - val_accuracy: 0.7607\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.6412 - accuracy: 0.7402 - val_loss: 0.6124 - val_accuracy: 0.7612\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.6188 - accuracy: 0.7468 - val_loss: 0.5900 - val_accuracy: 0.7662\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.6005 - accuracy: 0.7569 - val_loss: 0.5922 - val_accuracy: 0.7625\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.5882 - accuracy: 0.7589 - val_loss: 0.5781 - val_accuracy: 0.7721\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.5740 - accuracy: 0.7690 - val_loss: 0.5547 - val_accuracy: 0.7810\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 664us/step - loss: 0.5516 - accuracy: 0.7761 - val_loss: 0.5579 - val_accuracy: 0.7757\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 680us/step - loss: 0.5411 - accuracy: 0.7828 - val_loss: 0.5464 - val_accuracy: 0.7835\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.5418 - accuracy: 0.7816 - val_loss: 0.5502 - val_accuracy: 0.7803\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.5440 - accuracy: 0.7782 - val_loss: 0.5385 - val_accuracy: 0.7819\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 662us/step - loss: 0.5256 - accuracy: 0.7848 - val_loss: 0.5569 - val_accuracy: 0.7780\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 664us/step - loss: 0.5160 - accuracy: 0.7889 - val_loss: 0.5426 - val_accuracy: 0.7903\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5001 - accuracy: 0.7963 - val_loss: 0.5633 - val_accuracy: 0.7812\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.4847 - accuracy: 0.8033 - val_loss: 0.5713 - val_accuracy: 0.7762\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.4840 - accuracy: 0.8002 - val_loss: 0.5564 - val_accuracy: 0.7935\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 696us/step - loss: 0.4612 - accuracy: 0.8140 - val_loss: 0.5564 - val_accuracy: 0.7844\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.4609 - accuracy: 0.8150 - val_loss: 0.5545 - val_accuracy: 0.7878\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.4749 - accuracy: 0.8081 - val_loss: 0.5724 - val_accuracy: 0.7782\n",
      "3416/3416 [==============================] - 1s 196us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 0.9351 - accuracy: 0.5653 - val_loss: 0.8424 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 670us/step - loss: 0.8477 - accuracy: 0.6273 - val_loss: 0.7915 - val_accuracy: 0.6441\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 678us/step - loss: 0.7980 - accuracy: 0.6424 - val_loss: 0.7334 - val_accuracy: 0.6874\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 674us/step - loss: 0.7483 - accuracy: 0.6740 - val_loss: 0.7019 - val_accuracy: 0.7088\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.7223 - accuracy: 0.6988 - val_loss: 0.6552 - val_accuracy: 0.7384\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 675us/step - loss: 0.6856 - accuracy: 0.7204 - val_loss: 0.6274 - val_accuracy: 0.7541\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 675us/step - loss: 0.6524 - accuracy: 0.7405 - val_loss: 0.6106 - val_accuracy: 0.7605\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 675us/step - loss: 0.6171 - accuracy: 0.7538 - val_loss: 0.5897 - val_accuracy: 0.7684\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 678us/step - loss: 0.6041 - accuracy: 0.7573 - val_loss: 0.5923 - val_accuracy: 0.7678\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 677us/step - loss: 0.5839 - accuracy: 0.7664 - val_loss: 0.6038 - val_accuracy: 0.7511\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5954 - accuracy: 0.7610 - val_loss: 0.5821 - val_accuracy: 0.7810\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 674us/step - loss: 0.5773 - accuracy: 0.7670 - val_loss: 0.5613 - val_accuracy: 0.7725\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5699 - accuracy: 0.7714 - val_loss: 0.5759 - val_accuracy: 0.7675\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5590 - accuracy: 0.7730 - val_loss: 0.5577 - val_accuracy: 0.7785\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 675us/step - loss: 0.5315 - accuracy: 0.7875 - val_loss: 0.5487 - val_accuracy: 0.7821\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 5s 677us/step - loss: 0.5291 - accuracy: 0.7901 - val_loss: 0.5589 - val_accuracy: 0.7762\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5142 - accuracy: 0.7974 - val_loss: 0.5553 - val_accuracy: 0.7816\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 677us/step - loss: 0.5128 - accuracy: 0.7949 - val_loss: 0.5579 - val_accuracy: 0.7848\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5131 - accuracy: 0.7920 - val_loss: 0.5415 - val_accuracy: 0.7823\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 678us/step - loss: 0.4875 - accuracy: 0.8074 - val_loss: 0.5303 - val_accuracy: 0.7905\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 675us/step - loss: 0.4829 - accuracy: 0.8090 - val_loss: 0.5535 - val_accuracy: 0.7837\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 700us/step - loss: 0.4732 - accuracy: 0.8109 - val_loss: 0.5570 - val_accuracy: 0.7814\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 679us/step - loss: 0.4762 - accuracy: 0.8125 - val_loss: 0.5513 - val_accuracy: 0.7851\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 678us/step - loss: 0.4673 - accuracy: 0.8140 - val_loss: 0.5564 - val_accuracy: 0.7814\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 674us/step - loss: 0.4539 - accuracy: 0.8185 - val_loss: 0.5373 - val_accuracy: 0.7903\n",
      "3416/3416 [==============================] - 1s 195us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 0.9490 - accuracy: 0.5546 - val_loss: 0.8350 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 662us/step - loss: 0.8835 - accuracy: 0.6137 - val_loss: 0.8561 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 662us/step - loss: 0.8607 - accuracy: 0.6164 - val_loss: 0.7855 - val_accuracy: 0.6503\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 661us/step - loss: 0.7909 - accuracy: 0.6481 - val_loss: 0.7220 - val_accuracy: 0.6988\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.7400 - accuracy: 0.6780 - val_loss: 0.6985 - val_accuracy: 0.6997\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 660us/step - loss: 0.7389 - accuracy: 0.6770 - val_loss: 0.7211 - val_accuracy: 0.6976\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.7299 - accuracy: 0.6936 - val_loss: 0.6527 - val_accuracy: 0.7543\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.6680 - accuracy: 0.7327 - val_loss: 0.6460 - val_accuracy: 0.7402\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 664us/step - loss: 0.6469 - accuracy: 0.7437 - val_loss: 0.6067 - val_accuracy: 0.7575\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.6168 - accuracy: 0.7522 - val_loss: 0.5897 - val_accuracy: 0.7666\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 662us/step - loss: 0.6128 - accuracy: 0.7499 - val_loss: 0.5779 - val_accuracy: 0.7641\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.5861 - accuracy: 0.7652 - val_loss: 0.5717 - val_accuracy: 0.7696\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.5776 - accuracy: 0.7706 - val_loss: 0.5680 - val_accuracy: 0.7700\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 662us/step - loss: 0.5572 - accuracy: 0.7774 - val_loss: 0.5704 - val_accuracy: 0.7650\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.5560 - accuracy: 0.7739 - val_loss: 0.5840 - val_accuracy: 0.7664\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.5615 - accuracy: 0.7724 - val_loss: 0.5837 - val_accuracy: 0.7696\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 681us/step - loss: 0.5458 - accuracy: 0.7850 - val_loss: 0.5552 - val_accuracy: 0.7764\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 669us/step - loss: 0.5241 - accuracy: 0.7911 - val_loss: 0.5766 - val_accuracy: 0.7787\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.5214 - accuracy: 0.7929 - val_loss: 0.5480 - val_accuracy: 0.7801\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.5057 - accuracy: 0.7938 - val_loss: 0.5470 - val_accuracy: 0.7812\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 685us/step - loss: 0.5086 - accuracy: 0.7878 - val_loss: 0.5625 - val_accuracy: 0.7771\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 681us/step - loss: 0.5062 - accuracy: 0.7990 - val_loss: 0.5377 - val_accuracy: 0.7869\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.4879 - accuracy: 0.8047 - val_loss: 0.5375 - val_accuracy: 0.7880\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 662us/step - loss: 0.4699 - accuracy: 0.8134 - val_loss: 0.5458 - val_accuracy: 0.7826\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.4583 - accuracy: 0.8198 - val_loss: 0.5445 - val_accuracy: 0.7860\n",
      "3416/3416 [==============================] - 1s 197us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 6s 837us/step - loss: 0.9843 - accuracy: 0.5610 - val_loss: 0.8735 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.8987 - accuracy: 0.6197 - val_loss: 0.8658 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.8659 - accuracy: 0.6224 - val_loss: 0.7506 - val_accuracy: 0.6728\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.7967 - accuracy: 0.6664 - val_loss: 0.6846 - val_accuracy: 0.7195\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.7361 - accuracy: 0.7018 - val_loss: 0.6310 - val_accuracy: 0.7477\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 460us/step - loss: 0.6968 - accuracy: 0.7149 - val_loss: 0.6184 - val_accuracy: 0.7505\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 450us/step - loss: 0.6632 - accuracy: 0.7310 - val_loss: 0.5962 - val_accuracy: 0.7568\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.6535 - accuracy: 0.7361 - val_loss: 0.5942 - val_accuracy: 0.7602\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.6441 - accuracy: 0.7392 - val_loss: 0.6011 - val_accuracy: 0.7632\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 3s 449us/step - loss: 0.6289 - accuracy: 0.7458 - val_loss: 0.5682 - val_accuracy: 0.7725\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.6151 - accuracy: 0.7469 - val_loss: 0.5741 - val_accuracy: 0.7680\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.6038 - accuracy: 0.7551 - val_loss: 0.5585 - val_accuracy: 0.7789\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.5918 - accuracy: 0.7641 - val_loss: 0.5554 - val_accuracy: 0.7778\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 3s 446us/step - loss: 0.5830 - accuracy: 0.7598 - val_loss: 0.5544 - val_accuracy: 0.7764\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 3s 446us/step - loss: 0.5828 - accuracy: 0.7668 - val_loss: 0.5500 - val_accuracy: 0.7771\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.6051 - accuracy: 0.7583 - val_loss: 0.5652 - val_accuracy: 0.7739\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.5768 - accuracy: 0.7705 - val_loss: 0.5618 - val_accuracy: 0.7739\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 446us/step - loss: 0.5776 - accuracy: 0.7657 - val_loss: 0.5546 - val_accuracy: 0.7830\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.5714 - accuracy: 0.7695 - val_loss: 0.5518 - val_accuracy: 0.7782\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.5595 - accuracy: 0.7698 - val_loss: 0.5354 - val_accuracy: 0.7842\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.5540 - accuracy: 0.7763 - val_loss: 0.5478 - val_accuracy: 0.7814\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 3s 447us/step - loss: 0.5385 - accuracy: 0.7821 - val_loss: 0.5455 - val_accuracy: 0.7851\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 3s 445us/step - loss: 0.5321 - accuracy: 0.7818 - val_loss: 0.5373 - val_accuracy: 0.7814\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 3s 448us/step - loss: 0.5342 - accuracy: 0.7835 - val_loss: 0.5780 - val_accuracy: 0.7653\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 445us/step - loss: 0.5495 - accuracy: 0.7813 - val_loss: 0.5261 - val_accuracy: 0.7896\n",
      "3416/3416 [==============================] - 0s 138us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 6s 826us/step - loss: 0.9879 - accuracy: 0.5924 - val_loss: 0.8355 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 466us/step - loss: 0.8833 - accuracy: 0.6270 - val_loss: 0.8199 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 495us/step - loss: 0.8257 - accuracy: 0.6342 - val_loss: 0.7454 - val_accuracy: 0.6851\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 3s 466us/step - loss: 0.7574 - accuracy: 0.6733 - val_loss: 0.6831 - val_accuracy: 0.7247\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 3s 463us/step - loss: 0.7072 - accuracy: 0.7089 - val_loss: 0.6266 - val_accuracy: 0.7468\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 469us/step - loss: 0.6719 - accuracy: 0.7272 - val_loss: 0.6328 - val_accuracy: 0.7416\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 461us/step - loss: 0.6446 - accuracy: 0.7419 - val_loss: 0.5848 - val_accuracy: 0.7616\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 3s 466us/step - loss: 0.6225 - accuracy: 0.7529 - val_loss: 0.5953 - val_accuracy: 0.7609\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.6322 - accuracy: 0.7466 - val_loss: 0.5687 - val_accuracy: 0.7748\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5999 - accuracy: 0.7597 - val_loss: 0.5939 - val_accuracy: 0.7639\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.6125 - accuracy: 0.7523 - val_loss: 0.5773 - val_accuracy: 0.7721\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5892 - accuracy: 0.7698 - val_loss: 0.5627 - val_accuracy: 0.7714\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 3s 465us/step - loss: 0.5733 - accuracy: 0.7736 - val_loss: 0.5546 - val_accuracy: 0.7791\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5716 - accuracy: 0.7725 - val_loss: 0.5593 - val_accuracy: 0.7771\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 3s 466us/step - loss: 0.5680 - accuracy: 0.7747 - val_loss: 0.5506 - val_accuracy: 0.7782\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 462us/step - loss: 0.5632 - accuracy: 0.7752 - val_loss: 0.5581 - val_accuracy: 0.7730\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5581 - accuracy: 0.7750 - val_loss: 0.5474 - val_accuracy: 0.7832\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 466us/step - loss: 0.5509 - accuracy: 0.7818 - val_loss: 0.5495 - val_accuracy: 0.7773\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5448 - accuracy: 0.7826 - val_loss: 0.5457 - val_accuracy: 0.7801\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5380 - accuracy: 0.7892 - val_loss: 0.5416 - val_accuracy: 0.7855\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 3s 467us/step - loss: 0.5359 - accuracy: 0.7875 - val_loss: 0.5393 - val_accuracy: 0.7851\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 3s 465us/step - loss: 0.5321 - accuracy: 0.7888 - val_loss: 0.5454 - val_accuracy: 0.7867\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5349 - accuracy: 0.7885 - val_loss: 0.5630 - val_accuracy: 0.7807\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 3s 465us/step - loss: 0.5383 - accuracy: 0.7809 - val_loss: 0.5391 - val_accuracy: 0.7801\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 464us/step - loss: 0.5212 - accuracy: 0.7941 - val_loss: 0.5368 - val_accuracy: 0.7901\n",
      "3416/3416 [==============================] - 0s 139us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 6s 824us/step - loss: 0.9961 - accuracy: 0.5836 - val_loss: 0.8377 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 3s 453us/step - loss: 0.9054 - accuracy: 0.6162 - val_loss: 0.8377 - val_accuracy: 0.6407\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.8473 - accuracy: 0.6263 - val_loss: 0.7376 - val_accuracy: 0.6860\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 3s 453us/step - loss: 0.7812 - accuracy: 0.6653 - val_loss: 0.6822 - val_accuracy: 0.7172\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.7283 - accuracy: 0.6951 - val_loss: 0.6608 - val_accuracy: 0.7338\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 3s 454us/step - loss: 0.6971 - accuracy: 0.7152 - val_loss: 0.6231 - val_accuracy: 0.7502\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.6573 - accuracy: 0.7336 - val_loss: 0.6007 - val_accuracy: 0.7577\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.6379 - accuracy: 0.7419 - val_loss: 0.5886 - val_accuracy: 0.7587\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 3s 453us/step - loss: 0.6243 - accuracy: 0.7468 - val_loss: 0.5937 - val_accuracy: 0.7589\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.6139 - accuracy: 0.7542 - val_loss: 0.5737 - val_accuracy: 0.7664\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 3s 451us/step - loss: 0.6038 - accuracy: 0.7569 - val_loss: 0.5704 - val_accuracy: 0.7671\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 3s 455us/step - loss: 0.5977 - accuracy: 0.7605 - val_loss: 0.5809 - val_accuracy: 0.7659\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6832/6832 [==============================] - 3s 477us/step - loss: 0.5845 - accuracy: 0.7676 - val_loss: 0.5553 - val_accuracy: 0.7755\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 3s 454us/step - loss: 0.5896 - accuracy: 0.7598 - val_loss: 0.5940 - val_accuracy: 0.7641\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.5880 - accuracy: 0.7645 - val_loss: 0.5722 - val_accuracy: 0.7760\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 3s 455us/step - loss: 0.5914 - accuracy: 0.7660 - val_loss: 0.5661 - val_accuracy: 0.7700\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 3s 453us/step - loss: 0.5705 - accuracy: 0.7695 - val_loss: 0.5587 - val_accuracy: 0.7762\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 3s 455us/step - loss: 0.5594 - accuracy: 0.7784 - val_loss: 0.5455 - val_accuracy: 0.7780\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.5546 - accuracy: 0.7774 - val_loss: 0.5465 - val_accuracy: 0.7816\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 3s 455us/step - loss: 0.5393 - accuracy: 0.7823 - val_loss: 0.5488 - val_accuracy: 0.7807\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 3s 453us/step - loss: 0.5417 - accuracy: 0.7848 - val_loss: 0.5419 - val_accuracy: 0.7864\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.5428 - accuracy: 0.7819 - val_loss: 0.5368 - val_accuracy: 0.7855\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.5286 - accuracy: 0.7883 - val_loss: 0.5408 - val_accuracy: 0.7844\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 3s 456us/step - loss: 0.5270 - accuracy: 0.7907 - val_loss: 0.5367 - val_accuracy: 0.7857\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 3s 452us/step - loss: 0.5229 - accuracy: 0.7873 - val_loss: 0.5403 - val_accuracy: 0.7878\n",
      "3416/3416 [==============================] - 0s 139us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 0.9707 - accuracy: 0.5638 - val_loss: 0.8390 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 674us/step - loss: 0.8665 - accuracy: 0.6208 - val_loss: 0.8071 - val_accuracy: 0.6507\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 673us/step - loss: 0.8517 - accuracy: 0.6257 - val_loss: 0.7714 - val_accuracy: 0.6437\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 670us/step - loss: 0.8097 - accuracy: 0.6475 - val_loss: 0.7211 - val_accuracy: 0.6951\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 5s 669us/step - loss: 0.7849 - accuracy: 0.6620 - val_loss: 0.6984 - val_accuracy: 0.7047\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 668us/step - loss: 0.7536 - accuracy: 0.6787 - val_loss: 0.6765 - val_accuracy: 0.7170\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 668us/step - loss: 0.7252 - accuracy: 0.6910 - val_loss: 0.6484 - val_accuracy: 0.7229\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.7074 - accuracy: 0.6931 - val_loss: 0.6448 - val_accuracy: 0.7174\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 668us/step - loss: 0.6914 - accuracy: 0.7106 - val_loss: 0.6068 - val_accuracy: 0.7550\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.6665 - accuracy: 0.7332 - val_loss: 0.5954 - val_accuracy: 0.7605\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 668us/step - loss: 0.6430 - accuracy: 0.7471 - val_loss: 0.5890 - val_accuracy: 0.7664\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 668us/step - loss: 0.6270 - accuracy: 0.7485 - val_loss: 0.5730 - val_accuracy: 0.7687\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 680us/step - loss: 0.6136 - accuracy: 0.7537 - val_loss: 0.5712 - val_accuracy: 0.7719\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.6048 - accuracy: 0.7559 - val_loss: 0.5729 - val_accuracy: 0.7730\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 670us/step - loss: 0.5913 - accuracy: 0.7613 - val_loss: 0.5543 - val_accuracy: 0.7828\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 5s 697us/step - loss: 0.5748 - accuracy: 0.7734 - val_loss: 0.5478 - val_accuracy: 0.7791\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 669us/step - loss: 0.5710 - accuracy: 0.7743 - val_loss: 0.5528 - val_accuracy: 0.7814\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 669us/step - loss: 0.5663 - accuracy: 0.7693 - val_loss: 0.5529 - val_accuracy: 0.7807\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 673us/step - loss: 0.5659 - accuracy: 0.7736 - val_loss: 0.5443 - val_accuracy: 0.7844\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 670us/step - loss: 0.5605 - accuracy: 0.7771 - val_loss: 0.5480 - val_accuracy: 0.7828\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 670us/step - loss: 0.5488 - accuracy: 0.7775 - val_loss: 0.5704 - val_accuracy: 0.7812\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 671us/step - loss: 0.5426 - accuracy: 0.7809 - val_loss: 0.5410 - val_accuracy: 0.7837\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 671us/step - loss: 0.5325 - accuracy: 0.7829 - val_loss: 0.5358 - val_accuracy: 0.7930\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 673us/step - loss: 0.5305 - accuracy: 0.7863 - val_loss: 0.5392 - val_accuracy: 0.7842\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 669us/step - loss: 0.5124 - accuracy: 0.7963 - val_loss: 0.5625 - val_accuracy: 0.7760\n",
      "3416/3416 [==============================] - 1s 198us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 0.9941 - accuracy: 0.5871 - val_loss: 0.8354 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.8821 - accuracy: 0.6269 - val_loss: 0.7941 - val_accuracy: 0.6409\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.8349 - accuracy: 0.6295 - val_loss: 0.7577 - val_accuracy: 0.6457\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.7928 - accuracy: 0.6461 - val_loss: 0.7219 - val_accuracy: 0.6942\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.7449 - accuracy: 0.6743 - val_loss: 0.6853 - val_accuracy: 0.7006\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.7209 - accuracy: 0.6910 - val_loss: 0.7071 - val_accuracy: 0.7006\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.7031 - accuracy: 0.7103 - val_loss: 0.6520 - val_accuracy: 0.7366\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.6610 - accuracy: 0.7390 - val_loss: 0.6129 - val_accuracy: 0.7548\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.6391 - accuracy: 0.7540 - val_loss: 0.6017 - val_accuracy: 0.7587\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.6241 - accuracy: 0.7497 - val_loss: 0.5711 - val_accuracy: 0.7721\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.6162 - accuracy: 0.7537 - val_loss: 0.5959 - val_accuracy: 0.7659\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 663us/step - loss: 0.6021 - accuracy: 0.7645 - val_loss: 0.5681 - val_accuracy: 0.7737\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 672us/step - loss: 0.5834 - accuracy: 0.7701 - val_loss: 0.5625 - val_accuracy: 0.7773\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 685us/step - loss: 0.5718 - accuracy: 0.7784 - val_loss: 0.5520 - val_accuracy: 0.7764\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 672us/step - loss: 0.5827 - accuracy: 0.7730 - val_loss: 0.5621 - val_accuracy: 0.7766\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.5638 - accuracy: 0.7771 - val_loss: 0.5535 - val_accuracy: 0.7798\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.5563 - accuracy: 0.7875 - val_loss: 0.5527 - val_accuracy: 0.7780\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.5515 - accuracy: 0.7818 - val_loss: 0.5478 - val_accuracy: 0.7805\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 666us/step - loss: 0.5490 - accuracy: 0.7860 - val_loss: 0.5498 - val_accuracy: 0.7735\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 664us/step - loss: 0.5360 - accuracy: 0.7867 - val_loss: 0.5388 - val_accuracy: 0.7846\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.5178 - accuracy: 0.7989 - val_loss: 0.5368 - val_accuracy: 0.7878\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 665us/step - loss: 0.5250 - accuracy: 0.7984 - val_loss: 0.5505 - val_accuracy: 0.7864\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 664us/step - loss: 0.5212 - accuracy: 0.7904 - val_loss: 0.5412 - val_accuracy: 0.7855\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 664us/step - loss: 0.5117 - accuracy: 0.7986 - val_loss: 0.5317 - val_accuracy: 0.7848\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 667us/step - loss: 0.4943 - accuracy: 0.8075 - val_loss: 0.5334 - val_accuracy: 0.7883\n",
      "3416/3416 [==============================] - 1s 196us/step\n",
      "Train on 6832 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "6832/6832 [==============================] - 8s 1ms/step - loss: 1.0506 - accuracy: 0.5799 - val_loss: 0.8530 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "6832/6832 [==============================] - 5s 673us/step - loss: 0.8885 - accuracy: 0.6162 - val_loss: 0.7871 - val_accuracy: 0.6409\n",
      "Epoch 3/25\n",
      "6832/6832 [==============================] - 5s 675us/step - loss: 0.8341 - accuracy: 0.6237 - val_loss: 0.7525 - val_accuracy: 0.6835\n",
      "Epoch 4/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.7894 - accuracy: 0.6578 - val_loss: 0.7128 - val_accuracy: 0.6888\n",
      "Epoch 5/25\n",
      "6832/6832 [==============================] - 5s 675us/step - loss: 0.7376 - accuracy: 0.6824 - val_loss: 0.6613 - val_accuracy: 0.7168\n",
      "Epoch 6/25\n",
      "6832/6832 [==============================] - 5s 674us/step - loss: 0.6970 - accuracy: 0.7002 - val_loss: 0.6359 - val_accuracy: 0.7427\n",
      "Epoch 7/25\n",
      "6832/6832 [==============================] - 5s 674us/step - loss: 0.6697 - accuracy: 0.7276 - val_loss: 0.5979 - val_accuracy: 0.7575\n",
      "Epoch 8/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.6490 - accuracy: 0.7377 - val_loss: 0.5934 - val_accuracy: 0.7630\n",
      "Epoch 9/25\n",
      "6832/6832 [==============================] - 5s 694us/step - loss: 0.6269 - accuracy: 0.7497 - val_loss: 0.5824 - val_accuracy: 0.7646\n",
      "Epoch 10/25\n",
      "6832/6832 [==============================] - 5s 677us/step - loss: 0.6213 - accuracy: 0.7522 - val_loss: 0.5829 - val_accuracy: 0.7664\n",
      "Epoch 11/25\n",
      "6832/6832 [==============================] - 5s 678us/step - loss: 0.6004 - accuracy: 0.7621 - val_loss: 0.5640 - val_accuracy: 0.7730\n",
      "Epoch 12/25\n",
      "6832/6832 [==============================] - 5s 674us/step - loss: 0.5841 - accuracy: 0.7652 - val_loss: 0.6034 - val_accuracy: 0.7473\n",
      "Epoch 13/25\n",
      "6832/6832 [==============================] - 5s 701us/step - loss: 0.5921 - accuracy: 0.7602 - val_loss: 0.5683 - val_accuracy: 0.7719\n",
      "Epoch 14/25\n",
      "6832/6832 [==============================] - 5s 675us/step - loss: 0.5752 - accuracy: 0.7712 - val_loss: 0.5580 - val_accuracy: 0.7798\n",
      "Epoch 15/25\n",
      "6832/6832 [==============================] - 5s 677us/step - loss: 0.5569 - accuracy: 0.7854 - val_loss: 0.5529 - val_accuracy: 0.7773\n",
      "Epoch 16/25\n",
      "6832/6832 [==============================] - 5s 678us/step - loss: 0.5490 - accuracy: 0.7819 - val_loss: 0.5394 - val_accuracy: 0.7867\n",
      "Epoch 17/25\n",
      "6832/6832 [==============================] - 5s 680us/step - loss: 0.5398 - accuracy: 0.7862 - val_loss: 0.5547 - val_accuracy: 0.7803\n",
      "Epoch 18/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5465 - accuracy: 0.7780 - val_loss: 0.5389 - val_accuracy: 0.7835\n",
      "Epoch 19/25\n",
      "6832/6832 [==============================] - 5s 677us/step - loss: 0.5447 - accuracy: 0.7844 - val_loss: 0.5463 - val_accuracy: 0.7821\n",
      "Epoch 20/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5349 - accuracy: 0.7834 - val_loss: 0.5608 - val_accuracy: 0.7819\n",
      "Epoch 21/25\n",
      "6832/6832 [==============================] - 5s 678us/step - loss: 0.5219 - accuracy: 0.7913 - val_loss: 0.5502 - val_accuracy: 0.7880\n",
      "Epoch 22/25\n",
      "6832/6832 [==============================] - 5s 676us/step - loss: 0.5085 - accuracy: 0.8018 - val_loss: 0.5261 - val_accuracy: 0.7935\n",
      "Epoch 23/25\n",
      "6832/6832 [==============================] - 5s 690us/step - loss: 0.5014 - accuracy: 0.8002 - val_loss: 0.5266 - val_accuracy: 0.7930\n",
      "Epoch 24/25\n",
      "6832/6832 [==============================] - 5s 677us/step - loss: 0.4906 - accuracy: 0.8046 - val_loss: 0.5280 - val_accuracy: 0.7933\n",
      "Epoch 25/25\n",
      "6832/6832 [==============================] - 5s 681us/step - loss: 0.4862 - accuracy: 0.8113 - val_loss: 0.5357 - val_accuracy: 0.7919\n",
      "3416/3416 [==============================] - 1s 198us/step\n",
      "Train on 10248 samples, validate on 4392 samples\n",
      "Epoch 1/25\n",
      "10248/10248 [==============================] - 7s 693us/step - loss: 0.9423 - accuracy: 0.5846 - val_loss: 0.8239 - val_accuracy: 0.6407\n",
      "Epoch 2/25\n",
      "10248/10248 [==============================] - 4s 435us/step - loss: 0.8326 - accuracy: 0.6292 - val_loss: 0.7538 - val_accuracy: 0.6801\n",
      "Epoch 3/25\n",
      "10248/10248 [==============================] - 4s 432us/step - loss: 0.7569 - accuracy: 0.6763 - val_loss: 0.6664 - val_accuracy: 0.7270\n",
      "Epoch 4/25\n",
      "10248/10248 [==============================] - 4s 435us/step - loss: 0.7041 - accuracy: 0.7132 - val_loss: 0.6089 - val_accuracy: 0.7550\n",
      "Epoch 5/25\n",
      "10248/10248 [==============================] - 4s 435us/step - loss: 0.6577 - accuracy: 0.7345 - val_loss: 0.5772 - val_accuracy: 0.7637\n",
      "Epoch 6/25\n",
      "10248/10248 [==============================] - 4s 437us/step - loss: 0.6311 - accuracy: 0.7425 - val_loss: 0.5741 - val_accuracy: 0.7662\n",
      "Epoch 7/25\n",
      "10248/10248 [==============================] - 4s 436us/step - loss: 0.6141 - accuracy: 0.7550 - val_loss: 0.5649 - val_accuracy: 0.7739\n",
      "Epoch 8/25\n",
      "10248/10248 [==============================] - 4s 436us/step - loss: 0.6135 - accuracy: 0.7547 - val_loss: 0.5706 - val_accuracy: 0.7776\n",
      "Epoch 9/25\n",
      "10248/10248 [==============================] - 4s 436us/step - loss: 0.5994 - accuracy: 0.7653 - val_loss: 0.5685 - val_accuracy: 0.7721\n",
      "Epoch 10/25\n",
      "10248/10248 [==============================] - 4s 435us/step - loss: 0.5876 - accuracy: 0.7647 - val_loss: 0.5592 - val_accuracy: 0.7753\n",
      "Epoch 11/25\n",
      "10248/10248 [==============================] - 4s 437us/step - loss: 0.5862 - accuracy: 0.7665 - val_loss: 0.5836 - val_accuracy: 0.7691\n",
      "Epoch 12/25\n",
      "10248/10248 [==============================] - 5s 456us/step - loss: 0.5915 - accuracy: 0.7629 - val_loss: 0.5724 - val_accuracy: 0.7684\n",
      "Epoch 13/25\n",
      "10248/10248 [==============================] - 4s 436us/step - loss: 0.5750 - accuracy: 0.7701 - val_loss: 0.5389 - val_accuracy: 0.7816\n",
      "Epoch 14/25\n",
      "10248/10248 [==============================] - 5s 444us/step - loss: 0.5564 - accuracy: 0.7786 - val_loss: 0.5288 - val_accuracy: 0.7837\n",
      "Epoch 15/25\n",
      "10248/10248 [==============================] - 4s 435us/step - loss: 0.5561 - accuracy: 0.7751 - val_loss: 0.5477 - val_accuracy: 0.7832\n",
      "Epoch 16/25\n",
      "10248/10248 [==============================] - 4s 436us/step - loss: 0.5492 - accuracy: 0.7778 - val_loss: 0.5315 - val_accuracy: 0.7871\n",
      "Epoch 17/25\n",
      "10248/10248 [==============================] - 4s 434us/step - loss: 0.5453 - accuracy: 0.7806 - val_loss: 0.5295 - val_accuracy: 0.7885\n",
      "Epoch 18/25\n",
      "10248/10248 [==============================] - 4s 437us/step - loss: 0.5463 - accuracy: 0.7842 - val_loss: 0.5422 - val_accuracy: 0.7880\n",
      "Epoch 19/25\n",
      "10248/10248 [==============================] - 4s 434us/step - loss: 0.5452 - accuracy: 0.7801 - val_loss: 0.5283 - val_accuracy: 0.7930\n",
      "Epoch 20/25\n",
      "10248/10248 [==============================] - 4s 437us/step - loss: 0.5369 - accuracy: 0.7873 - val_loss: 0.5355 - val_accuracy: 0.7842\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10248/10248 [==============================] - 4s 435us/step - loss: 0.5333 - accuracy: 0.7909 - val_loss: 0.5129 - val_accuracy: 0.7996\n",
      "Epoch 22/25\n",
      "10248/10248 [==============================] - 4s 436us/step - loss: 0.5157 - accuracy: 0.7942 - val_loss: 0.5095 - val_accuracy: 0.7999\n",
      "Epoch 23/25\n",
      "10248/10248 [==============================] - 4s 437us/step - loss: 0.5173 - accuracy: 0.7948 - val_loss: 0.5297 - val_accuracy: 0.7917\n",
      "Epoch 24/25\n",
      "10248/10248 [==============================] - 4s 434us/step - loss: 0.5295 - accuracy: 0.7898 - val_loss: 0.5312 - val_accuracy: 0.7908\n",
      "Epoch 25/25\n",
      "10248/10248 [==============================] - 4s 434us/step - loss: 0.5108 - accuracy: 0.7941 - val_loss: 0.5123 - val_accuracy: 0.7962\n",
      "GridSearchCV took 1381.59 seconds for 4 candidate parameter settings.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3f2d22b35c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n\u001b[1;32m     12\u001b[0m       % (time() - start, len(grid_search.cv_results_['params'])))\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "# run grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model=KerasClassifier(build_fn=create_model)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_dist)\n",
    "\n",
    "start = time()\n",
    "history=grid_search.fit(x_train, y_train, validation_data=(x_val,y_val))\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.770 (std: 0.006)\n",
      "Parameters: {'batch_size': 1000, 'dropout_rate': 0.5, 'epochs': 25, 'learning_rate': 0.01, 'lstm_cells': 64, 'lstm_layers': 2, 'neurons': 64, 'optimizer': 'adam'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.768 (std: 0.003)\n",
      "Parameters: {'batch_size': 1000, 'dropout_rate': 0.2, 'epochs': 25, 'learning_rate': 0.01, 'lstm_cells': 64, 'lstm_layers': 3, 'neurons': 64, 'optimizer': 'adam'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.764 (std: 0.002)\n",
      "Parameters: {'batch_size': 1000, 'dropout_rate': 0.5, 'epochs': 25, 'learning_rate': 0.01, 'lstm_cells': 64, 'lstm_layers': 3, 'neurons': 64, 'optimizer': 'adam'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "report(grid_search.cv_results_)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10248/10248 [==============================] - 6s 589us/step - loss: 0.9583 - accuracy: 0.5973\n",
      "Epoch 2/25\n",
      "10248/10248 [==============================] - 4s 390us/step - loss: 0.8592 - accuracy: 0.6206\n",
      "Epoch 3/25\n",
      "10248/10248 [==============================] - 4s 404us/step - loss: 0.7787 - accuracy: 0.6585\n",
      "Epoch 4/25\n",
      "10248/10248 [==============================] - 4s 439us/step - loss: 0.7057 - accuracy: 0.7157\n",
      "Epoch 5/25\n",
      "10248/10248 [==============================] - 4s 383us/step - loss: 0.6668 - accuracy: 0.7309\n",
      "Epoch 6/25\n",
      "10248/10248 [==============================] - 4s 383us/step - loss: 0.6454 - accuracy: 0.7403\n",
      "Epoch 7/25\n",
      "10248/10248 [==============================] - 4s 383us/step - loss: 0.6226 - accuracy: 0.7528\n",
      "Epoch 8/25\n",
      "10248/10248 [==============================] - 4s 382us/step - loss: 0.6077 - accuracy: 0.7572\n",
      "Epoch 9/25\n",
      "10248/10248 [==============================] - 4s 397us/step - loss: 0.6031 - accuracy: 0.7610\n",
      "Epoch 10/25\n",
      "10248/10248 [==============================] - 4s 382us/step - loss: 0.6012 - accuracy: 0.7614\n",
      "Epoch 11/25\n",
      "10248/10248 [==============================] - 4s 384us/step - loss: 0.5815 - accuracy: 0.7684\n",
      "Epoch 12/25\n",
      "10248/10248 [==============================] - 4s 384us/step - loss: 0.5749 - accuracy: 0.7681\n",
      "Epoch 13/25\n",
      "10248/10248 [==============================] - 4s 382us/step - loss: 0.5692 - accuracy: 0.7715\n",
      "Epoch 14/25\n",
      "10248/10248 [==============================] - 4s 383us/step - loss: 0.5656 - accuracy: 0.7722\n",
      "Epoch 15/25\n",
      "10248/10248 [==============================] - 4s 384us/step - loss: 0.5535 - accuracy: 0.7776\n",
      "Epoch 16/25\n",
      "10248/10248 [==============================] - 4s 384us/step - loss: 0.5561 - accuracy: 0.7783\n",
      "Epoch 17/25\n",
      "10248/10248 [==============================] - 4s 383us/step - loss: 0.5470 - accuracy: 0.7835\n",
      "Epoch 18/25\n",
      "10248/10248 [==============================] - 4s 383us/step - loss: 0.5473 - accuracy: 0.7807\n",
      "Epoch 19/25\n",
      "10248/10248 [==============================] - 4s 385us/step - loss: 0.5405 - accuracy: 0.7843\n",
      "Epoch 20/25\n",
      "10248/10248 [==============================] - 4s 385us/step - loss: 0.5348 - accuracy: 0.7847\n",
      "Epoch 21/25\n",
      "10248/10248 [==============================] - 4s 396us/step - loss: 0.5350 - accuracy: 0.7874\n",
      "Epoch 22/25\n",
      "10248/10248 [==============================] - 4s 384us/step - loss: 0.5263 - accuracy: 0.7872\n",
      "Epoch 23/25\n",
      "10248/10248 [==============================] - 4s 384us/step - loss: 0.5184 - accuracy: 0.7942\n",
      "Epoch 24/25\n",
      "10248/10248 [==============================] - 4s 384us/step - loss: 0.5097 - accuracy: 0.7930\n",
      "Epoch 25/25\n",
      "10248/10248 [==============================] - 4s 396us/step - loss: 0.5127 - accuracy: 0.7927\n",
      "The model took 106.23 seconds with optimal hyperparamenters.\n"
     ]
    }
   ],
   "source": [
    "# creating model with the optimal hyperparameters\n",
    "\n",
    "model=create_model(optimizer='adam',neurons=64,lstm_layers=2,lstm_cells=64,learning_rate=0.01,dropout_rate=0.5)\n",
    "\n",
    "start = time()\n",
    "history=model.fit(x_train2,y_train2, epochs=25, batch_size=1000)\n",
    "print(\"The model took %.2f seconds with optimal hyperparamenters.\" %(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 426  191   77]\n",
      " [  39 2653  122]\n",
      " [  53  413  418]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       518\n",
      "           1       0.94      0.81      0.87      3257\n",
      "           2       0.47      0.68      0.56       617\n",
      "\n",
      "    accuracy                           0.80      4392\n",
      "   macro avg       0.68      0.77      0.71      4392\n",
      "weighted avg       0.84      0.80      0.81      4392\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = grid_search.predict(x_test)\n",
    "\n",
    "CM = confusion_matrix(np.argmax(y_test, axis = 1), Y_pred)\n",
    "print(\"\\n\"+\"Confusion Matrix:\" + \"\\n\")\n",
    "print(CM)\n",
    "\n",
    "print(\"\\n\"+\"Classification Report\"+\"\\n\")\n",
    "print(classification_report(Y_pred,np.argmax(y_test, axis = 1)))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the confusion matrix an the classification repot we can say that the model behaves well for the three tweet sentiment, with a little bias for the negative sentiments.\n",
    "\n",
    "On the othe hand, the accuracy and the loss graphs give evidence that a better training can be done and we can expect better results. For example, more epochs or a smaller batch size.\n",
    "\n",
    "The best model was found though Grid Search because the F1 Score in this case is 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackabuse.com/python-for-nlp-movie-sentiment-analysis-using-deep-learning-in-keras/\n",
    "https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
